{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLE - Exercise 2 -\n",
    "\n",
    "## Assignment\n",
    "In this exercise, you shall experiment with a number of (simple) algorithms on several datasets. The aim is to get a feeling how well each of these algorithms works, and whether there are differences depending on the dataset.\n",
    "\n",
    "The datasets are\n",
    "* [Iris](https://archive.ics.uci.edu/ml/datasets/Iris), for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "* [Handwritten digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits), of which we only use the test set of 1797 instances; for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)\n",
    "* If you are a group of three (see below): [Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)); skip the ID field; in Python: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "\n",
    "The classifiers you shall use are\n",
    "* k-NN (with 3 different values for k)\n",
    "* Naive Bayes\n",
    "* Perceptron, and\n",
    "* Decision Trees with 3 different parameter settings (e.g. some pre-pruning setting, different split criterion, ...)\n",
    "\n",
    "For each dataset, you shall train and evaluate each classifier (with parameter variations), and then compute several evaluation metrics\n",
    "* Effectiveness: Accuracy, and 1 more of your choice (precision, recall, F1, ...\n",
    "* Efficiency: runtime for training & testing\n",
    "* As evaluation set splitting technique, you shall use once the holdout method with 2/3 training and the rest for testing, and once cross validation with 5 folds.\n",
    "\n",
    "You shall present these results in a tabular form, with one table for each dataset & splitting combination approach.\n",
    "\n",
    "Then describe the results, and analyse e.g.:\n",
    "* Which classifiers work best?\n",
    "* Are there differences between the datasets?\n",
    "* Are the differences in the efficiency measurements?\n",
    "* How is the runtime changing with the different data sets?\n",
    "* ...\n",
    "\n",
    "You can solve this exercise alone, or in a group of two students. If you form a group, you need to extend your scope, by\n",
    "* Adding a third dataset, namely breast cancer wisconsin\n",
    "* For k-NN, using 5 different values for k instead of 3, and use both weighted and uniform distance (i.e. a total of 10 combinations); for Decision Trees, also add 3 more parameter variations\n",
    "* Adding a third efficiency evaluation metric\n",
    "\n",
    "Your submission shall contain\n",
    "* The textual report\n",
    "* All code samples and\n",
    "* All data sets (if not already included in your software package, e.g. Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## k-NN\n",
    "\n",
    "### Iris"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}