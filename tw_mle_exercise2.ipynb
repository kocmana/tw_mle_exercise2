{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLE - Exercise 2 - Comparative Experimentation\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "## Assignment\n",
    "In this exercise, you shall experiment with a number of (simple) algorithms on several datasets. The aim is to get a feeling how well each of these algorithms works, and whether there are differences depending on the dataset.\n",
    "\n",
    "The datasets are\n",
    "* [Iris](https://archive.ics.uci.edu/ml/datasets/Iris), for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "* [Handwritten digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits), of which we only use the test set of 1797 instances; for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)\n",
    "* If you are a group of three (see below): [Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)); skip the ID field; in Python: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "\n",
    "The classifiers you shall use are\n",
    "* k-NN (with 3 different values for k)\n",
    "* Naive Bayes\n",
    "* Perceptron, and\n",
    "* Decision Trees with 3 different parameter settings (e.g. some pre-pruning setting, different split criterion, ...)\n",
    "\n",
    "For each dataset, you shall train and evaluate each classifier (with parameter variations), and then compute several evaluation metrics\n",
    "* Effectiveness: Accuracy, and 1 more of your choice (precision, recall, F1, ...\n",
    "* Efficiency: runtime for training & testing\n",
    "* As evaluation set splitting technique, you shall use once the holdout method with 2/3 training and the rest for testing, and once cross validation with 5 folds.\n",
    "\n",
    "You shall present these results in a tabular form, with one table for each dataset & splitting combination approach.\n",
    "\n",
    "Iris/5-folds | Accuracy | Precision| Training time | Testing time\n",
    "---|---|---|---|---|---\n",
    "k-NN (3-NN) | .85 | .82 | 0.1 sec | 27 sec\n",
    "Naive Bayes | .72 | .82 | 1 sec | 2 sec\n",
    "Decision Tree | .92 | .76 | 5 sec | 2 sec\n",
    "... | ... | ...| ... | ...\n",
    "\n",
    "Then describe the results, and analyse e.g.:\n",
    "* Which classifiers work best?\n",
    "* Are there differences between the datasets?\n",
    "* Are the differences in the efficiency measurements?\n",
    "* How is the runtime changing with the different data sets?\n",
    "* ...\n",
    "\n",
    "You can solve this exercise alone, or in a group of two students. If you form a group, you need to extend your scope, by\n",
    "* Adding a third dataset, namely breast cancer wisconsin\n",
    "* For k-NN, using 5 different values for k instead of 3, and use both weighted and uniform distance (i.e. a total of 10 combinations); for Decision Trees, also add 3 more parameter variations\n",
    "* Adding a third efficiency evaluation metric\n",
    "\n",
    "## Deliverables\n",
    "Your submission shall contain\n",
    "* The textual report\n",
    "* All code samples and\n",
    "* All data sets (if not already included in your software package, e.g. Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sources used\n",
    "* Scikit documentation\n",
    "* https://simonhessner.de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-multi-class-problem/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#General Imports\n",
    "import numpy as numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "#Global variables\n",
    "randomState=24  # change the state with the numeric parts of your matrikelnummer; if you are in a group, use the sume of the numeric parts\n",
    "                # se19m024\n",
    "averagingApproach = 'macro'\n",
    "zero_divisionApproach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averagingApproach, zero_division=zero_divisionApproach),\n",
    "            'Recall': make_scorer(recall_score, average=averagingApproach, zero_division=zero_divisionApproach)}\n",
    "\n",
    "#Helper funcitons\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(numpy.average(results)) + \" std: \" + str(numpy.std(results)) # + \" values: \" + str(results)\n",
    "\n",
    "def parse_k_fold_timings(results):\n",
    "    return \"total: \" + str(numpy.sum(results)) + \" values: \" + str(results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn_results = []\n",
    "\n",
    "# parameters for k-NN\n",
    "n_neighbors = [5,10,20]\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        # train the k-NN\n",
    "        classifier = neighbors.KNeighborsClassifier(n)\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0 )\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "knn_results_df = pd.DataFrame(knn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "The results below show extremely high accuracy for kNN  in the Iris dataset both with N values of 5, 10 and 20. However, best results were yielded for a N value of 2.\n",
    "Additionally, results of the k-fold approach show good consistency of results across 5 folds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris      kNN       n=5  holdout     0.96  0.958333  0.968254   \n2    iris      kNN      n=10  holdout     0.92  0.925926  0.936508   \n4    iris      kNN      n=20  holdout     0.88       0.9  0.904762   \n\n  time training time testing  \n0   0.000997305  0.000997543  \n2             0   0.00199509  \n4   0.000997782   0.00199437  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.96</td>\n      <td>0.958333</td>\n      <td>0.968254</td>\n      <td>0.000997305</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0</td>\n      <td>0.00199509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.9</td>\n      <td>0.904762</td>\n      <td>0.000997782</td>\n      <td>0.00199437</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris      kNN       n=5  k-fold   \n3    iris      kNN      n=10  k-fold   \n5    iris      kNN      n=20  k-fold   \n\n                                         accuracy  \\\n1               m: 0.96 std: 0.038873012632301994   \n3  m: 0.9733333333333334 std: 0.05333333333333332   \n5  m: 0.9466666666666667 std: 0.04521553322083511   \n\n                                         precision  \\\n1   m: 0.9610774410774411 std: 0.03826764858710283   \n3               m: 0.975 std: 0.049999999999999996   \n5  m: 0.9517676767676768 std: 0.042228383872089235   \n\n                                            recall  \\\n1                 m: 0.96 std: 0.03887301263230201   \n3  m: 0.9733333333333334 std: 0.053333333333333365   \n5   m: 0.9466666666666667 std: 0.04521553322083516   \n\n                                       time training  \\\n1  total: 0.000997304916381836 values: [0.       ...   \n3                total: 0.0 values: [0. 0. 0. 0. 0.]   \n5                total: 0.0 values: [0. 0. 0. 0. 0.]   \n\n                                        time testing  \n1  total: 0.01296544075012207 values: [0.00299215...  \n3  total: 0.014959573745727539 values: [0.0029919...  \n5  total: 0.00997304916381836 values: [0.00199437...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.96 std: 0.038873012632301994</td>\n      <td>m: 0.9610774410774411 std: 0.03826764858710283</td>\n      <td>m: 0.96 std: 0.03887301263230201</td>\n      <td>total: 0.000997304916381836 values: [0.       ...</td>\n      <td>total: 0.01296544075012207 values: [0.00299215...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.05333333333333332</td>\n      <td>m: 0.975 std: 0.049999999999999996</td>\n      <td>m: 0.9733333333333334 std: 0.053333333333333365</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.014959573745727539 values: [0.0029919...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083511</td>\n      <td>m: 0.9517676767676768 std: 0.042228383872089235</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083516</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.00997304916381836 values: [0.00199437...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='holdout')])\n",
    "display(knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "Similar to the Iris dataset, the results below also show extremely high accuracy for kNN for a image recognition dataset both with N values of 5, 10 and 20. However, best results were yielded for a N value of 10.\n",
    "Additionally, results of the k-fold approach again show good consistency of results across 5 folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset approach arguments    split  accuracy precision    recall  \\\n6   digits      kNN       n=5  holdout  0.983165  0.983364  0.983174   \n8   digits      kNN      n=10  holdout  0.976431  0.976702  0.976281   \n10  digits      kNN      n=20  holdout  0.961279  0.962286  0.961089   \n\n   time training time testing  \n6      0.0159564     0.106744  \n8      0.0159283    0.0917542  \n10     0.0259006     0.109705  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.983165</td>\n      <td>0.983364</td>\n      <td>0.983174</td>\n      <td>0.0159564</td>\n      <td>0.106744</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.976431</td>\n      <td>0.976702</td>\n      <td>0.976281</td>\n      <td>0.0159283</td>\n      <td>0.0917542</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.961279</td>\n      <td>0.962286</td>\n      <td>0.961089</td>\n      <td>0.0259006</td>\n      <td>0.109705</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset approach arguments   split  \\\n7   digits      kNN       n=5  k-fold   \n9   digits      kNN      n=10  k-fold   \n11  digits      kNN      n=20  k-fold   \n\n                                           accuracy  \\\n7   m: 0.9883163107397092 std: 0.005388572629804117   \n9   m: 0.9805277004023523 std: 0.007241231361602902   \n11  m: 0.9705060352831941 std: 0.006724967766856801   \n\n                                          precision  \\\n7   m: 0.9887866449971712 std: 0.005222598238459717   \n9    m: 0.9816830468409415 std: 0.00662931853158472   \n11  m: 0.9717214434156635 std: 0.006292571449491544   \n\n                                              recall  \\\n7   m: 0.9882804905746081 std: 0.0053145264097686756   \n9     m: 0.9804048249930603 std: 0.00715395193374626   \n11    m: 0.9702434451257981 std: 0.00681107277803136   \n\n                                        time training  \\\n7   total: 0.10268950462341309 values: [0.02191734...   \n9   total: 0.10272455215454102 values: [0.01894951...   \n11  total: 0.11178374290466309 values: [0.02097678...   \n\n                                         time testing  \n7   total: 0.3243260383605957 values: [0.06796765 ...  \n9   total: 0.3530890941619873 values: [0.06386065 ...  \n11  total: 0.38193178176879883 values: [0.06678843...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.9883163107397092 std: 0.005388572629804117</td>\n      <td>m: 0.9887866449971712 std: 0.005222598238459717</td>\n      <td>m: 0.9882804905746081 std: 0.0053145264097686756</td>\n      <td>total: 0.10268950462341309 values: [0.02191734...</td>\n      <td>total: 0.3243260383605957 values: [0.06796765 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9805277004023523 std: 0.007241231361602902</td>\n      <td>m: 0.9816830468409415 std: 0.00662931853158472</td>\n      <td>m: 0.9804048249930603 std: 0.00715395193374626</td>\n      <td>total: 0.10272455215454102 values: [0.01894951...</td>\n      <td>total: 0.3530890941619873 values: [0.06386065 ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9705060352831941 std: 0.006724967766856801</td>\n      <td>m: 0.9717214434156635 std: 0.006292571449491544</td>\n      <td>m: 0.9702434451257981 std: 0.00681107277803136</td>\n      <td>total: 0.11178374290466309 values: [0.02097678...</td>\n      <td>total: 0.38193178176879883 values: [0.06678843...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='holdout')])\n",
    "display(knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "bayes_results = []\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = naive_bayes.GaussianNB()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                        scoring = scoring,\n",
    "                        cv = number_of_folds,\n",
    "                        error_score = 0 )\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "bayes_results_df = pd.DataFrame(bayes_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "\n",
    "Results below indicate good accuracy, precision and recall for the dataset. Accuracy is a bit lower than for k-NN but still very good.\n",
    "\n",
    "Consistency of results as measured by a five fold cross validation seems good."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris    bayes      none  holdout      0.9   0.90305  0.912698   \n\n  time training time testing  \n0             0            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris    bayes      none  k-fold   \n\n                                         accuracy  \\\n1  m: 0.9533333333333334 std: 0.03399346342395189   \n\n                                        precision  \\\n1  m: 0.9550168350168351 std: 0.03375719358407477   \n\n                                          recall  \\\n1  m: 0.9533333333333334 std: 0.0339934634239519   \n\n                                       time training  \\\n1  total: 0.002988100051879883 values: [0.       ...   \n\n                                        time testing  \n1  total: 0.005987405776977539 values: [0.0009973...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9533333333333334 std: 0.03399346342395189</td>\n      <td>m: 0.9550168350168351 std: 0.03375719358407477</td>\n      <td>m: 0.9533333333333334 std: 0.0339934634239519</td>\n      <td>total: 0.002988100051879883 values: [0.       ...</td>\n      <td>total: 0.005987405776977539 values: [0.0009973...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='holdout')])\n",
    "display(bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "Similar to the Iris dataset, Bayes yielded also sufficient accuracy, precision and recall for the digits dataset. Again, accuracy is a bit lower than for k-NN but still very good.\n",
    "The difference between the Iris and Digit dataset is noteworthy however. It seems like Bayes is not a similarly good approach for this data set. This may be related to the much higher dimensionality of the digit dataset.\n",
    "Also for this dataset, consistency of results as measured by a five fold cross validation seems good."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split  accuracy precision    recall  \\\n2  digits    bayes      none  holdout  0.833333  0.850641  0.833908   \n\n  time training time testing  \n2    0.00299025  0.000997305  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.850641</td>\n      <td>0.833908</td>\n      <td>0.00299025</td>\n      <td>0.000997305</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n3  digits    bayes      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.8324945837202105 std: 0.009286635323422067   \n\n                                         precision  \\\n3  m: 0.8598088622118409 std: 0.015147678383072103   \n\n                                            recall  \\\n3  m: 0.8325454614278144 std: 0.009764788694682724   \n\n                                       time training  \\\n3  total: 0.012965917587280273 values: [0.0029923...   \n\n                                        time testing  \n3  total: 0.011965274810791016 values: [0.0019936...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.8324945837202105 std: 0.009286635323422067</td>\n      <td>m: 0.8598088622118409 std: 0.015147678383072103</td>\n      <td>m: 0.8325454614278144 std: 0.009764788694682724</td>\n      <td>total: 0.012965917587280273 values: [0.0029923...</td>\n      <td>total: 0.011965274810791016 values: [0.0019936...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='holdout')])\n",
    "display(bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Analysis using Bayes on the *Iris* dataset show good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "* Analysis using Bayes on the *Digit Dataset* show still good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "\n",
    "However, compared to k NN, the results for this data set are significantly lower for Bayes. While this was similar for the Iris dataset, with lower accuracy for bayes than for the k-nn, the difference was not similarly strong.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "perceptron_results = []\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = linear_model.Perceptron()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                    scoring = scoring,\n",
    "                    cv = number_of_folds,\n",
    "                    error_score = 0 )\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "perceptron_results_df = pd.DataFrame(perceptron_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split accuracy precision recall  \\\n0    iris  perceptron      none  holdout     0.34  0.432624    0.4   \n\n  time training time testing  \n0    0.00199413            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.34</td>\n      <td>0.432624</td>\n      <td>0.4</td>\n      <td>0.00199413</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split                          accuracy  \\\n1    iris  perceptron      none  k-fold  m: 0.74 std: 0.10413666234542207   \n\n                                        precision  \\\n1  m: 0.6742889463477699 std: 0.19998100699035673   \n\n                             recall  \\\n1  m: 0.74 std: 0.10413666234542203   \n\n                                       time training  \\\n1  total: 0.008975982666015625 values: [0.0019948...   \n\n                                        time testing  \n1  total: 0.004987478256225586 values: [0.0009987...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.74 std: 0.10413666234542207</td>\n      <td>m: 0.6742889463477699 std: 0.19998100699035673</td>\n      <td>m: 0.74 std: 0.10413666234542203</td>\n      <td>total: 0.008975982666015625 values: [0.0019948...</td>\n      <td>total: 0.004987478256225586 values: [0.0009987...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='holdout')])\n",
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split  accuracy precision   recall  \\\n2  digits  perceptron      none  holdout  0.939394   0.94141  0.93962   \n\n  time training time testing  \n2     0.0239413  0.000996351  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.939394</td>\n      <td>0.94141</td>\n      <td>0.93962</td>\n      <td>0.0239413</td>\n      <td>0.000996351</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split  \\\n3  digits  perceptron      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.9410229031259671 std: 0.015849668296257387   \n\n                                        precision  \\\n3  m: 0.9472330796425998 std: 0.01371753706347739   \n\n                                            recall  \\\n3  m: 0.9410189264895147 std: 0.015777826142176866   \n\n                                       time training  \\\n3  total: 0.15159392356872559 values: [0.02991819...   \n\n                                        time testing  \n3  total: 0.008939266204833984 values: [0.0009942...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9410229031259671 std: 0.015849668296257387</td>\n      <td>m: 0.9472330796425998 std: 0.01371753706347739</td>\n      <td>m: 0.9410189264895147 std: 0.015777826142176866</td>\n      <td>total: 0.15159392356872559 values: [0.02991819...</td>\n      <td>total: 0.008939266204833984 values: [0.0009942...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='holdout')])\n",
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Analysis using the Perceptron approach on the *Iris dataset* show low values for accuracy, precision and recall with extremely low training and testing time.\n",
    "Compared to both Bayes and k NN, the results for this data set are significantly lower.\n",
    "* Analysis using the Perceptron approach on the *Digits dataset* show very good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "Both Bayes and kNN yielded comparable results. The difference between the Digit and Iris dataset show Perceptron's high susceptibility to the data it is used for."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "decision_tree_results = []\n",
    "\n",
    "# Parameters for the decision tree\n",
    "max_depth_arguments = [5,10,15]\n",
    "min_samples_leaf_arguments = [2,20,40]\n",
    "splitting_approaches_arguments = ['random', 'best']\n",
    "argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                        min_samples_leaf_arguments,\n",
    "                                        splitting_approaches_arguments))\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "        splitting_approach = argumentTuple[2]\n",
    "\n",
    "        # train the k-NN\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = splitting_approach)\n",
    "\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': argumentTuple,\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': argumentTuple,\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "decision_tree_results_df = pd.DataFrame(decision_tree_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split accuracy  \\\n0     iris  Decision Tree Classifier    (5, 2, random)  holdout     0.88   \n2     iris  Decision Tree Classifier      (5, 2, best)  holdout      0.9   \n4     iris  Decision Tree Classifier   (5, 20, random)  holdout     0.48   \n6     iris  Decision Tree Classifier     (5, 20, best)  holdout      0.9   \n8     iris  Decision Tree Classifier   (5, 40, random)  holdout     0.28   \n10    iris  Decision Tree Classifier     (5, 40, best)  holdout     0.54   \n12    iris  Decision Tree Classifier   (10, 2, random)  holdout      0.9   \n14    iris  Decision Tree Classifier     (10, 2, best)  holdout      0.9   \n16    iris  Decision Tree Classifier  (10, 20, random)  holdout     0.48   \n18    iris  Decision Tree Classifier    (10, 20, best)  holdout      0.9   \n20    iris  Decision Tree Classifier  (10, 40, random)  holdout     0.28   \n22    iris  Decision Tree Classifier    (10, 40, best)  holdout     0.54   \n24    iris  Decision Tree Classifier   (15, 2, random)  holdout      0.9   \n26    iris  Decision Tree Classifier     (15, 2, best)  holdout      0.9   \n28    iris  Decision Tree Classifier  (15, 20, random)  holdout     0.48   \n30    iris  Decision Tree Classifier    (15, 20, best)  holdout      0.9   \n32    iris  Decision Tree Classifier  (15, 40, random)  holdout     0.28   \n34    iris  Decision Tree Classifier    (15, 40, best)  holdout     0.54   \n\n    precision    recall time training time testing  \n0    0.890278  0.865079             0            0  \n2     0.90305  0.912698             0  0.000995636  \n4        0.45  0.555556             0            0  \n6     0.90305  0.912698   0.000997782            0  \n8   0.0933333  0.333333   0.000994921            0  \n10    0.41533  0.619048             0            0  \n12   0.894956  0.904762             0            0  \n14    0.90305  0.912698             0  0.000996828  \n16       0.45  0.555556   0.000997305            0  \n18    0.90305  0.912698             0   0.00099802  \n20  0.0933333  0.333333             0            0  \n22    0.41533  0.619048   0.000997782            0  \n24   0.894956  0.904762   0.000997782            0  \n26    0.90305  0.912698   0.000998497            0  \n28       0.45  0.555556             0            0  \n30    0.90305  0.912698   0.000988245            0  \n32  0.0933333  0.333333             0            0  \n34    0.41533  0.619048    0.00102901            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.890278</td>\n      <td>0.865079</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000995636</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0.000994921</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000996828</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.00099802</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000998497</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000988245</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.00102901</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n1     iris  Decision Tree Classifier    (5, 2, random)  k-fold   \n3     iris  Decision Tree Classifier      (5, 2, best)  k-fold   \n5     iris  Decision Tree Classifier   (5, 20, random)  k-fold   \n7     iris  Decision Tree Classifier     (5, 20, best)  k-fold   \n9     iris  Decision Tree Classifier   (5, 40, random)  k-fold   \n11    iris  Decision Tree Classifier     (5, 40, best)  k-fold   \n13    iris  Decision Tree Classifier   (10, 2, random)  k-fold   \n15    iris  Decision Tree Classifier     (10, 2, best)  k-fold   \n17    iris  Decision Tree Classifier  (10, 20, random)  k-fold   \n19    iris  Decision Tree Classifier    (10, 20, best)  k-fold   \n21    iris  Decision Tree Classifier  (10, 40, random)  k-fold   \n23    iris  Decision Tree Classifier    (10, 40, best)  k-fold   \n25    iris  Decision Tree Classifier   (15, 2, random)  k-fold   \n27    iris  Decision Tree Classifier     (15, 2, best)  k-fold   \n29    iris  Decision Tree Classifier  (15, 20, random)  k-fold   \n31    iris  Decision Tree Classifier    (15, 20, best)  k-fold   \n33    iris  Decision Tree Classifier  (15, 40, random)  k-fold   \n35    iris  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n1    m: 0.8800000000000001 std: 0.05416025603090639   \n3    m: 0.9400000000000001 std: 0.04422166387140532   \n5   m: 0.5599999999999999 std: 0.024944382578492935   \n7    m: 0.9266666666666667 std: 0.04422166387140532   \n9                    m: 0.3333333333333333 std: 0.0   \n11   m: 0.7666666666666666 std: 0.12292725943057185   \n13   m: 0.9199999999999999 std: 0.04521553322083511   \n15   m: 0.9400000000000001 std: 0.04422166387140532   \n17  m: 0.5599999999999999 std: 0.024944382578492935   \n19   m: 0.9266666666666667 std: 0.04422166387140532   \n21                   m: 0.3333333333333333 std: 0.0   \n23   m: 0.7666666666666666 std: 0.12292725943057185   \n25   m: 0.9199999999999999 std: 0.04521553322083511   \n27   m: 0.9400000000000001 std: 0.04422166387140532   \n29  m: 0.5599999999999999 std: 0.024944382578492935   \n31   m: 0.9266666666666667 std: 0.04422166387140532   \n33                   m: 0.3333333333333333 std: 0.0   \n35   m: 0.7666666666666666 std: 0.12292725943057185   \n\n                                            precision  \\\n1      m: 0.9151709401709403 std: 0.02856862378351845   \n3      m: 0.9444949494949496 std: 0.04164152899506982   \n5    m: 0.47716293368467283 std: 0.004696804926703416   \n7      m: 0.9332491582491583 std: 0.04255264892173636   \n9   m: 0.11111111111111112 std: 1.3877787807814457...   \n11     m: 0.6693602693602694 std: 0.20784967494940076   \n13     m: 0.9307840307840308 std: 0.03813348030226439   \n15     m: 0.9444949494949496 std: 0.04164152899506982   \n17   m: 0.47716293368467283 std: 0.004696804926703416   \n19     m: 0.9332491582491583 std: 0.04255264892173636   \n21  m: 0.11111111111111112 std: 1.3877787807814457...   \n23     m: 0.6693602693602694 std: 0.20784967494940076   \n25     m: 0.9307840307840308 std: 0.03813348030226439   \n27     m: 0.9444949494949496 std: 0.04164152899506982   \n29   m: 0.47716293368467283 std: 0.004696804926703416   \n31     m: 0.9332491582491583 std: 0.04255264892173636   \n33  m: 0.11111111111111112 std: 1.3877787807814457...   \n35     m: 0.6693602693602694 std: 0.20784967494940076   \n\n                                             recall  \\\n1    m: 0.8799999999999999 std: 0.05416025603090637   \n3   m: 0.9400000000000001 std: 0.044221663871405366   \n5   m: 0.5599999999999999 std: 0.024944382578492935   \n7   m: 0.9266666666666665 std: 0.044221663871405345   \n9                    m: 0.3333333333333333 std: 0.0   \n11   m: 0.7666666666666666 std: 0.12292725943057183   \n13    m: 0.9199999999999999 std: 0.0452155332208351   \n15  m: 0.9400000000000001 std: 0.044221663871405366   \n17  m: 0.5599999999999999 std: 0.024944382578492935   \n19  m: 0.9266666666666665 std: 0.044221663871405345   \n21                   m: 0.3333333333333333 std: 0.0   \n23   m: 0.7666666666666666 std: 0.12292725943057183   \n25    m: 0.9199999999999999 std: 0.0452155332208351   \n27  m: 0.9400000000000001 std: 0.044221663871405366   \n29  m: 0.5599999999999999 std: 0.024944382578492935   \n31  m: 0.9266666666666665 std: 0.044221663871405345   \n33                   m: 0.3333333333333333 std: 0.0   \n35   m: 0.7666666666666666 std: 0.12292725943057183   \n\n                                        time training  \\\n1   total: 0.0029909610748291016 values: [0.000996...   \n3   total: 0.0039899349212646484 values: [0.000997...   \n5   total: 0.0009984970092773438 values: [0.      ...   \n7   total: 0.002992391586303711 values: [0.0009975...   \n9   total: 0.0029954910278320312 values: [0.001002...   \n11  total: 0.00498652458190918 values: [0.00099707...   \n13  total: 0.0029916763305664062 values: [0.000997...   \n15  total: 0.0009970664978027344 values: [0.      ...   \n17  total: 0.003989219665527344 values: [0.       ...   \n19  total: 0.002992391586303711 values: [0.       ...   \n21  total: 0.003988981246948242 values: [0.0009977...   \n23  total: 0.004987239837646484 values: [0.0009973...   \n25                total: 0.0 values: [0. 0. 0. 0. 0.]   \n27  total: 0.004975557327270508 values: [0.0009937...   \n29  total: 0.002956390380859375 values: [0.0009946...   \n31  total: 0.002009868621826172 values: [0.       ...   \n33  total: 0.0039103031158447266 values: [0.000969...   \n35  total: 0.0029611587524414062 values: [0.000965...   \n\n                                         time testing  \n1   total: 0.006982088088989258 values: [0.0009975...  \n3   total: 0.005985736846923828 values: [0.0009982...  \n5   total: 0.008977174758911133 values: [0.0019943...  \n7   total: 0.006968021392822266 values: [0.0009968...  \n9   total: 0.006973743438720703 values: [0.0009920...  \n11  total: 0.004986286163330078 values: [0.0009973...  \n13  total: 0.004986763000488281 values: [0.0009973...  \n15  total: 0.004986763000488281 values: [0.0009970...  \n17  total: 0.00498652458190918 values: [0.00099754...  \n19  total: 0.004985809326171875 values: [0.0009970...  \n21  total: 0.005984306335449219 values: [0.0009973...  \n23  total: 0.004987478256225586 values: [0.0009975...  \n25  total: 0.010005712509155273 values: [0.0019946...  \n27  total: 0.004998445510864258 values: [0.0009985...  \n29  total: 0.007015705108642578 values: [0.0009989...  \n31  total: 0.008897542953491211 values: [0.0009658...  \n33  total: 0.007031679153442383 values: [0.0020077...  \n35  total: 0.0050389766693115234 values: [0.001024...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8800000000000001 std: 0.05416025603090639</td>\n      <td>m: 0.9151709401709403 std: 0.02856862378351845</td>\n      <td>m: 0.8799999999999999 std: 0.05416025603090637</td>\n      <td>total: 0.0029909610748291016 values: [0.000996...</td>\n      <td>total: 0.006982088088989258 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.0039899349212646484 values: [0.000997...</td>\n      <td>total: 0.005985736846923828 values: [0.0009982...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0009984970092773438 values: [0.      ...</td>\n      <td>total: 0.008977174758911133 values: [0.0019943...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002992391586303711 values: [0.0009975...</td>\n      <td>total: 0.006968021392822266 values: [0.0009968...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0029954910278320312 values: [0.001002...</td>\n      <td>total: 0.006973743438720703 values: [0.0009920...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.00498652458190918 values: [0.00099707...</td>\n      <td>total: 0.004986286163330078 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0029916763305664062 values: [0.000997...</td>\n      <td>total: 0.004986763000488281 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.0009970664978027344 values: [0.      ...</td>\n      <td>total: 0.004986763000488281 values: [0.0009970...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.003989219665527344 values: [0.       ...</td>\n      <td>total: 0.00498652458190918 values: [0.00099754...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002992391586303711 values: [0.       ...</td>\n      <td>total: 0.004985809326171875 values: [0.0009970...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003988981246948242 values: [0.0009977...</td>\n      <td>total: 0.005984306335449219 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.004987239837646484 values: [0.0009973...</td>\n      <td>total: 0.004987478256225586 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.010005712509155273 values: [0.0019946...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.004975557327270508 values: [0.0009937...</td>\n      <td>total: 0.004998445510864258 values: [0.0009985...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.002956390380859375 values: [0.0009946...</td>\n      <td>total: 0.007015705108642578 values: [0.0009989...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002009868621826172 values: [0.       ...</td>\n      <td>total: 0.008897542953491211 values: [0.0009658...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0039103031158447266 values: [0.000969...</td>\n      <td>total: 0.007031679153442383 values: [0.0020077...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0029611587524414062 values: [0.000965...</td>\n      <td>total: 0.0050389766693115234 values: [0.001024...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetIris = datasets.load_iris();\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 10,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetIris.data, datasetIris.target),max_depth=5)\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='holdout')])\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split  accuracy  \\\n36  digits  Decision Tree Classifier    (5, 2, random)  holdout  0.673401   \n38  digits  Decision Tree Classifier      (5, 2, best)  holdout    0.6633   \n40  digits  Decision Tree Classifier   (5, 20, random)  holdout  0.643098   \n42  digits  Decision Tree Classifier     (5, 20, best)  holdout  0.658249   \n44  digits  Decision Tree Classifier   (5, 40, random)  holdout  0.624579   \n46  digits  Decision Tree Classifier     (5, 40, best)  holdout  0.607744   \n48  digits  Decision Tree Classifier   (10, 2, random)  holdout  0.821549   \n50  digits  Decision Tree Classifier     (10, 2, best)  holdout  0.833333   \n52  digits  Decision Tree Classifier  (10, 20, random)  holdout  0.742424   \n54  digits  Decision Tree Classifier    (10, 20, best)  holdout  0.794613   \n56  digits  Decision Tree Classifier  (10, 40, random)  holdout  0.621212   \n58  digits  Decision Tree Classifier    (10, 40, best)  holdout  0.734007   \n60  digits  Decision Tree Classifier   (15, 2, random)  holdout  0.826599   \n62  digits  Decision Tree Classifier     (15, 2, best)  holdout   0.83165   \n64  digits  Decision Tree Classifier  (15, 20, random)  holdout  0.742424   \n66  digits  Decision Tree Classifier    (15, 20, best)  holdout  0.794613   \n68  digits  Decision Tree Classifier  (15, 40, random)  holdout  0.621212   \n70  digits  Decision Tree Classifier    (15, 40, best)  holdout  0.734007   \n\n   precision    recall time training time testing  \n36  0.717454  0.677103    0.00299382            0  \n38  0.746121  0.663671    0.00900841            0  \n40  0.637573  0.641345    0.00399446  0.000993967  \n42  0.720075  0.657125    0.00897002  0.000971794  \n44  0.595066  0.623683    0.00299263            0  \n46   0.59806  0.604756    0.00797749  0.000996828  \n48  0.827151  0.822762    0.00598502  0.000996113  \n50   0.84214  0.836688     0.0139637            0  \n52  0.749126  0.743035    0.00398827            0  \n54   0.80054  0.797709    0.00997877  0.000995874  \n56  0.649174  0.622869    0.00299239  0.000998497  \n58  0.764335   0.73374     0.0109711  0.000998259  \n60  0.832276  0.828587    0.00498438            0  \n62  0.839983  0.835681     0.0149601            0  \n64  0.749126  0.743035    0.00598431            0  \n66   0.80054  0.797709     0.0119667            0  \n68  0.649174  0.622869    0.00299263  0.000997782  \n70  0.764335   0.73374    0.00997281            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.673401</td>\n      <td>0.717454</td>\n      <td>0.677103</td>\n      <td>0.00299382</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.6633</td>\n      <td>0.746121</td>\n      <td>0.663671</td>\n      <td>0.00900841</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.643098</td>\n      <td>0.637573</td>\n      <td>0.641345</td>\n      <td>0.00399446</td>\n      <td>0.000993967</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.658249</td>\n      <td>0.720075</td>\n      <td>0.657125</td>\n      <td>0.00897002</td>\n      <td>0.000971794</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.624579</td>\n      <td>0.595066</td>\n      <td>0.623683</td>\n      <td>0.00299263</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.607744</td>\n      <td>0.59806</td>\n      <td>0.604756</td>\n      <td>0.00797749</td>\n      <td>0.000996828</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.821549</td>\n      <td>0.827151</td>\n      <td>0.822762</td>\n      <td>0.00598502</td>\n      <td>0.000996113</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.84214</td>\n      <td>0.836688</td>\n      <td>0.0139637</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00398827</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00997877</td>\n      <td>0.000995874</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299239</td>\n      <td>0.000998497</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.0109711</td>\n      <td>0.000998259</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.826599</td>\n      <td>0.832276</td>\n      <td>0.828587</td>\n      <td>0.00498438</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.83165</td>\n      <td>0.839983</td>\n      <td>0.835681</td>\n      <td>0.0149601</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00598431</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.0119667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299263</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00997281</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n37  digits  Decision Tree Classifier    (5, 2, random)  k-fold   \n39  digits  Decision Tree Classifier      (5, 2, best)  k-fold   \n41  digits  Decision Tree Classifier   (5, 20, random)  k-fold   \n43  digits  Decision Tree Classifier     (5, 20, best)  k-fold   \n45  digits  Decision Tree Classifier   (5, 40, random)  k-fold   \n47  digits  Decision Tree Classifier     (5, 40, best)  k-fold   \n49  digits  Decision Tree Classifier   (10, 2, random)  k-fold   \n51  digits  Decision Tree Classifier     (10, 2, best)  k-fold   \n53  digits  Decision Tree Classifier  (10, 20, random)  k-fold   \n55  digits  Decision Tree Classifier    (10, 20, best)  k-fold   \n57  digits  Decision Tree Classifier  (10, 40, random)  k-fold   \n59  digits  Decision Tree Classifier    (10, 40, best)  k-fold   \n61  digits  Decision Tree Classifier   (15, 2, random)  k-fold   \n63  digits  Decision Tree Classifier     (15, 2, best)  k-fold   \n65  digits  Decision Tree Classifier  (15, 20, random)  k-fold   \n67  digits  Decision Tree Classifier    (15, 20, best)  k-fold   \n69  digits  Decision Tree Classifier  (15, 40, random)  k-fold   \n71  digits  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n37     m: 0.682799442896936 std: 0.0225789955736832   \n39  m: 0.6521990095945527 std: 0.029293764851288196   \n41  m: 0.6750278551532034 std: 0.040755563742608684   \n43   m: 0.642189724543485 std: 0.026859596447899876   \n45   m: 0.6282559579077684 std: 0.04962782791262363   \n47  m: 0.6271649644073042 std: 0.022340010709646117   \n49  m: 0.8492169606932837 std: 0.024701250873822116   \n51  m: 0.8497415660786135 std: 0.016289255420700997   \n53  m: 0.7334292788610337 std: 0.020905478914734647   \n55   m: 0.7879712163416899 std: 0.01638106112774851   \n57  m: 0.6956360259981429 std: 0.030311998503533933   \n59   m: 0.7551593933766635 std: 0.02118747834909684   \n61    m: 0.8480857319715259 std: 0.0160451900425344   \n63  m: 0.8503002166511916 std: 0.009784061096593345   \n65  m: 0.7334292788610337 std: 0.020905478914734647   \n67   m: 0.7879712163416899 std: 0.01638106112774851   \n69  m: 0.6956360259981429 std: 0.030311998503533933   \n71   m: 0.7551593933766635 std: 0.02118747834909684   \n\n                                          precision  \\\n37   m: 0.717660567564935 std: 0.026132446284686445   \n39   m: 0.7298174310895975 std: 0.01717008365700091   \n41  m: 0.6950497115958991 std: 0.061857032803490745   \n43    m: 0.703735266738326 std: 0.01501969790860612   \n45   m: 0.6253692157304211 std: 0.05839129334704999   \n47   m: 0.6660513441822741 std: 0.02980445680574132   \n49  m: 0.8535964619626707 std: 0.024247845316340284   \n51  m: 0.8559045305923447 std: 0.016949978229067093   \n53   m: 0.7394966477817702 std: 0.02134785363906439   \n55  m: 0.7966323249656977 std: 0.019183878519583475   \n57   m: 0.7156065230428587 std: 0.03517987997097763   \n59  m: 0.7708872928512271 std: 0.018327983630086836   \n61  m: 0.8518270691602231 std: 0.014618370518263432   \n63  m: 0.8570756527976207 std: 0.010812556072823007   \n65   m: 0.7394966477817702 std: 0.02134785363906439   \n67  m: 0.7966323249656977 std: 0.019183878519583475   \n69   m: 0.7156065230428587 std: 0.03517987997097763   \n71  m: 0.7708872928512271 std: 0.018327983630086836   \n\n                                             recall  \\\n37  m: 0.6822451106568753 std: 0.022306835943359964   \n39  m: 0.6520541549953315 std: 0.028721061472361847   \n41    m: 0.674860019683549 std: 0.04133979548873456   \n43  m: 0.6420215509627274 std: 0.026807715646732715   \n45  m: 0.6283112019582608 std: 0.050742761166004666   \n47  m: 0.6270297019708784 std: 0.022343553593636677   \n49   m: 0.848803896333308 std: 0.024983989383474584   \n51  m: 0.8496446109975521 std: 0.016132101050840803   \n53   m: 0.7331400055517703 std: 0.02089872408546371   \n55    m: 0.7882291114644057 std: 0.0162673398542481   \n57   m: 0.6946652282534636 std: 0.03080685318605075   \n59   m: 0.754918641330406 std: 0.021705452983571242   \n61   m: 0.847657531481061 std: 0.016500416901784897   \n63  m: 0.8501242334771746 std: 0.009676746964727485   \n65   m: 0.7331400055517703 std: 0.02089872408546371   \n67    m: 0.7882291114644057 std: 0.0162673398542481   \n69   m: 0.6946652282534636 std: 0.03080685318605075   \n71   m: 0.754918641330406 std: 0.021705452983571242   \n\n                                        time training  \\\n37  total: 0.02091217041015625 values: [0.00398803...   \n39  total: 0.05185675621032715 values: [0.00997257...   \n41  total: 0.024979591369628906 values: [0.0049858...   \n43  total: 0.06183505058288574 values: [0.01296616...   \n45  total: 0.022940874099731445 values: [0.0049877...   \n47  total: 0.054849863052368164 values: [0.0119662...   \n49  total: 0.035906076431274414 values: [0.0079789...   \n51  total: 0.08380770683288574 values: [0.01895046...   \n53  total: 0.024934053421020508 values: [0.004987 ...   \n55  total: 0.0777595043182373 values: [0.0149591  ...   \n57  total: 0.026928424835205078 values: [0.0059833...   \n59  total: 0.0688161849975586 values: [0.01396251 ...   \n61  total: 0.03790116310119629 values: [0.00698161...   \n63  total: 0.10072803497314453 values: [0.01894808...   \n65  total: 0.02891850471496582 values: [0.00498486...   \n67  total: 0.07380175590515137 values: [0.01396275...   \n69  total: 0.025930166244506836 values: [0.0049872...   \n71  total: 0.06183338165283203 values: [0.01196599...   \n\n                                         time testing  \n37  total: 0.007982969284057617 values: [0.0019989...  \n39  total: 0.009945154190063477 values: [0.0019941...  \n41  total: 0.010895013809204102 values: [0.001966 ...  \n43  total: 0.008976459503173828 values: [0.0009968...  \n45  total: 0.011968612670898438 values: [0.0029923...  \n47  total: 0.00897359848022461 values: [0.00099683...  \n49  total: 0.011968135833740234 values: [0.0029931...  \n51  total: 0.009973764419555664 values: [0.0019934...  \n53  total: 0.00797724723815918 values: [0.00199437...  \n55  total: 0.011968374252319336 values: [0.0019946...  \n57  total: 0.009973287582397461 values: [0.0019948...  \n59  total: 0.009972810745239258 values: [0.0019938...  \n61  total: 0.010967731475830078 values: [0.0019941...  \n63  total: 0.010973691940307617 values: [0.0019955...  \n65  total: 0.010972976684570312 values: [0.0019950...  \n67  total: 0.011967658996582031 values: [0.0039889...  \n69  total: 0.009973287582397461 values: [0.0019929...  \n71  total: 0.00997304916381836 values: [0.00199509...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.682799442896936 std: 0.0225789955736832</td>\n      <td>m: 0.717660567564935 std: 0.026132446284686445</td>\n      <td>m: 0.6822451106568753 std: 0.022306835943359964</td>\n      <td>total: 0.02091217041015625 values: [0.00398803...</td>\n      <td>total: 0.007982969284057617 values: [0.0019989...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6521990095945527 std: 0.029293764851288196</td>\n      <td>m: 0.7298174310895975 std: 0.01717008365700091</td>\n      <td>m: 0.6520541549953315 std: 0.028721061472361847</td>\n      <td>total: 0.05185675621032715 values: [0.00997257...</td>\n      <td>total: 0.009945154190063477 values: [0.0019941...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6750278551532034 std: 0.040755563742608684</td>\n      <td>m: 0.6950497115958991 std: 0.061857032803490745</td>\n      <td>m: 0.674860019683549 std: 0.04133979548873456</td>\n      <td>total: 0.024979591369628906 values: [0.0049858...</td>\n      <td>total: 0.010895013809204102 values: [0.001966 ...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.642189724543485 std: 0.026859596447899876</td>\n      <td>m: 0.703735266738326 std: 0.01501969790860612</td>\n      <td>m: 0.6420215509627274 std: 0.026807715646732715</td>\n      <td>total: 0.06183505058288574 values: [0.01296616...</td>\n      <td>total: 0.008976459503173828 values: [0.0009968...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6282559579077684 std: 0.04962782791262363</td>\n      <td>m: 0.6253692157304211 std: 0.05839129334704999</td>\n      <td>m: 0.6283112019582608 std: 0.050742761166004666</td>\n      <td>total: 0.022940874099731445 values: [0.0049877...</td>\n      <td>total: 0.011968612670898438 values: [0.0029923...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6271649644073042 std: 0.022340010709646117</td>\n      <td>m: 0.6660513441822741 std: 0.02980445680574132</td>\n      <td>m: 0.6270297019708784 std: 0.022343553593636677</td>\n      <td>total: 0.054849863052368164 values: [0.0119662...</td>\n      <td>total: 0.00897359848022461 values: [0.00099683...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8492169606932837 std: 0.024701250873822116</td>\n      <td>m: 0.8535964619626707 std: 0.024247845316340284</td>\n      <td>m: 0.848803896333308 std: 0.024983989383474584</td>\n      <td>total: 0.035906076431274414 values: [0.0079789...</td>\n      <td>total: 0.011968135833740234 values: [0.0029931...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8497415660786135 std: 0.016289255420700997</td>\n      <td>m: 0.8559045305923447 std: 0.016949978229067093</td>\n      <td>m: 0.8496446109975521 std: 0.016132101050840803</td>\n      <td>total: 0.08380770683288574 values: [0.01895046...</td>\n      <td>total: 0.009973764419555664 values: [0.0019934...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.024934053421020508 values: [0.004987 ...</td>\n      <td>total: 0.00797724723815918 values: [0.00199437...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.0777595043182373 values: [0.0149591  ...</td>\n      <td>total: 0.011968374252319336 values: [0.0019946...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.026928424835205078 values: [0.0059833...</td>\n      <td>total: 0.009973287582397461 values: [0.0019948...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.0688161849975586 values: [0.01396251 ...</td>\n      <td>total: 0.009972810745239258 values: [0.0019938...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8480857319715259 std: 0.0160451900425344</td>\n      <td>m: 0.8518270691602231 std: 0.014618370518263432</td>\n      <td>m: 0.847657531481061 std: 0.016500416901784897</td>\n      <td>total: 0.03790116310119629 values: [0.00698161...</td>\n      <td>total: 0.010967731475830078 values: [0.0019941...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8503002166511916 std: 0.009784061096593345</td>\n      <td>m: 0.8570756527976207 std: 0.010812556072823007</td>\n      <td>m: 0.8501242334771746 std: 0.009676746964727485</td>\n      <td>total: 0.10072803497314453 values: [0.01894808...</td>\n      <td>total: 0.010973691940307617 values: [0.0019955...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.02891850471496582 values: [0.00498486...</td>\n      <td>total: 0.010972976684570312 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.07380175590515137 values: [0.01396275...</td>\n      <td>total: 0.011967658996582031 values: [0.0039889...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.025930166244506836 values: [0.0049872...</td>\n      <td>total: 0.009973287582397461 values: [0.0019929...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.06183338165283203 values: [0.01196599...</td>\n      <td>total: 0.00997304916381836 values: [0.00199509...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDigits = datasets.load_digits();\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 10,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetDigits.data, datasetDigits.target),max_depth=5)\n",
    "\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='holdout')])\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Random and Best Splitting Approach for the Decision Tree on both the Iris and Digits Dataset:\n",
    "The overall results indicate that the \"best\" splitting parameter yields by far superior results compared to the \"random\" approach.\n",
    "* Min Sample Leaf Values: Additional analyses of the results from the previous step show that there is overfitting after a max depth of 2 with only limited benefits of additional splits.\n",
    "To counteract the creation of additional nodes, min_samples_leaf was added as parameter for an extensive high maximum depth (30).\n",
    "* Analysis using the Decision Tree approach on the Digits Dataset show a high relevance of the defined max tree depth for accuracy, precision and recall with extremely low training and testing time. For a max depth of 7, the resulting tree yields good results with limited overfitting. Potential subsequent pruning could further reduce overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overall Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "overall_results = knn_results + bayes_results + perceptron_results + decision_tree_results\n",
    "overall_results_df = pd.DataFrame(overall_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iris Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split accuracy  \\\n0     iris                       kNN               n=5  holdout     0.96   \n2     iris                       kNN              n=10  holdout     0.92   \n4     iris                       kNN              n=20  holdout     0.88   \n12    iris                     bayes              none  holdout      0.9   \n16    iris                perceptron              none  holdout     0.34   \n20    iris  Decision Tree Classifier    (5, 2, random)  holdout     0.88   \n22    iris  Decision Tree Classifier      (5, 2, best)  holdout      0.9   \n24    iris  Decision Tree Classifier   (5, 20, random)  holdout     0.48   \n26    iris  Decision Tree Classifier     (5, 20, best)  holdout      0.9   \n28    iris  Decision Tree Classifier   (5, 40, random)  holdout     0.28   \n30    iris  Decision Tree Classifier     (5, 40, best)  holdout     0.54   \n32    iris  Decision Tree Classifier   (10, 2, random)  holdout      0.9   \n34    iris  Decision Tree Classifier     (10, 2, best)  holdout      0.9   \n36    iris  Decision Tree Classifier  (10, 20, random)  holdout     0.48   \n38    iris  Decision Tree Classifier    (10, 20, best)  holdout      0.9   \n40    iris  Decision Tree Classifier  (10, 40, random)  holdout     0.28   \n42    iris  Decision Tree Classifier    (10, 40, best)  holdout     0.54   \n44    iris  Decision Tree Classifier   (15, 2, random)  holdout      0.9   \n46    iris  Decision Tree Classifier     (15, 2, best)  holdout      0.9   \n48    iris  Decision Tree Classifier  (15, 20, random)  holdout     0.48   \n50    iris  Decision Tree Classifier    (15, 20, best)  holdout      0.9   \n52    iris  Decision Tree Classifier  (15, 40, random)  holdout     0.28   \n54    iris  Decision Tree Classifier    (15, 40, best)  holdout     0.54   \n\n    precision    recall time training time testing  \n0    0.958333  0.968254   0.000997305  0.000997543  \n2    0.925926  0.936508             0   0.00199509  \n4         0.9  0.904762   0.000997782   0.00199437  \n12    0.90305  0.912698             0            0  \n16   0.432624       0.4    0.00199413            0  \n20   0.890278  0.865079             0            0  \n22    0.90305  0.912698             0  0.000995636  \n24       0.45  0.555556             0            0  \n26    0.90305  0.912698   0.000997782            0  \n28  0.0933333  0.333333   0.000994921            0  \n30    0.41533  0.619048             0            0  \n32   0.894956  0.904762             0            0  \n34    0.90305  0.912698             0  0.000996828  \n36       0.45  0.555556   0.000997305            0  \n38    0.90305  0.912698             0   0.00099802  \n40  0.0933333  0.333333             0            0  \n42    0.41533  0.619048   0.000997782            0  \n44   0.894956  0.904762   0.000997782            0  \n46    0.90305  0.912698   0.000998497            0  \n48       0.45  0.555556             0            0  \n50    0.90305  0.912698   0.000988245            0  \n52  0.0933333  0.333333             0            0  \n54    0.41533  0.619048    0.00102901            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.96</td>\n      <td>0.958333</td>\n      <td>0.968254</td>\n      <td>0.000997305</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0</td>\n      <td>0.00199509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.9</td>\n      <td>0.904762</td>\n      <td>0.000997782</td>\n      <td>0.00199437</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.34</td>\n      <td>0.432624</td>\n      <td>0.4</td>\n      <td>0.00199413</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.890278</td>\n      <td>0.865079</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000995636</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0.000994921</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000996828</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.00099802</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000997782</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000998497</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000988245</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.00102901</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n1     iris                       kNN               n=5  k-fold   \n3     iris                       kNN              n=10  k-fold   \n5     iris                       kNN              n=20  k-fold   \n13    iris                     bayes              none  k-fold   \n17    iris                perceptron              none  k-fold   \n21    iris  Decision Tree Classifier    (5, 2, random)  k-fold   \n23    iris  Decision Tree Classifier      (5, 2, best)  k-fold   \n25    iris  Decision Tree Classifier   (5, 20, random)  k-fold   \n27    iris  Decision Tree Classifier     (5, 20, best)  k-fold   \n29    iris  Decision Tree Classifier   (5, 40, random)  k-fold   \n31    iris  Decision Tree Classifier     (5, 40, best)  k-fold   \n33    iris  Decision Tree Classifier   (10, 2, random)  k-fold   \n35    iris  Decision Tree Classifier     (10, 2, best)  k-fold   \n37    iris  Decision Tree Classifier  (10, 20, random)  k-fold   \n39    iris  Decision Tree Classifier    (10, 20, best)  k-fold   \n41    iris  Decision Tree Classifier  (10, 40, random)  k-fold   \n43    iris  Decision Tree Classifier    (10, 40, best)  k-fold   \n45    iris  Decision Tree Classifier   (15, 2, random)  k-fold   \n47    iris  Decision Tree Classifier     (15, 2, best)  k-fold   \n49    iris  Decision Tree Classifier  (15, 20, random)  k-fold   \n51    iris  Decision Tree Classifier    (15, 20, best)  k-fold   \n53    iris  Decision Tree Classifier  (15, 40, random)  k-fold   \n55    iris  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n1                 m: 0.96 std: 0.038873012632301994   \n3    m: 0.9733333333333334 std: 0.05333333333333332   \n5    m: 0.9466666666666667 std: 0.04521553322083511   \n13   m: 0.9533333333333334 std: 0.03399346342395189   \n17                 m: 0.74 std: 0.10413666234542207   \n21   m: 0.8800000000000001 std: 0.05416025603090639   \n23   m: 0.9400000000000001 std: 0.04422166387140532   \n25  m: 0.5599999999999999 std: 0.024944382578492935   \n27   m: 0.9266666666666667 std: 0.04422166387140532   \n29                   m: 0.3333333333333333 std: 0.0   \n31   m: 0.7666666666666666 std: 0.12292725943057185   \n33   m: 0.9199999999999999 std: 0.04521553322083511   \n35   m: 0.9400000000000001 std: 0.04422166387140532   \n37  m: 0.5599999999999999 std: 0.024944382578492935   \n39   m: 0.9266666666666667 std: 0.04422166387140532   \n41                   m: 0.3333333333333333 std: 0.0   \n43   m: 0.7666666666666666 std: 0.12292725943057185   \n45   m: 0.9199999999999999 std: 0.04521553322083511   \n47   m: 0.9400000000000001 std: 0.04422166387140532   \n49  m: 0.5599999999999999 std: 0.024944382578492935   \n51   m: 0.9266666666666667 std: 0.04422166387140532   \n53                   m: 0.3333333333333333 std: 0.0   \n55   m: 0.7666666666666666 std: 0.12292725943057185   \n\n                                            precision  \\\n1      m: 0.9610774410774411 std: 0.03826764858710283   \n3                  m: 0.975 std: 0.049999999999999996   \n5     m: 0.9517676767676768 std: 0.042228383872089235   \n13     m: 0.9550168350168351 std: 0.03375719358407477   \n17     m: 0.6742889463477699 std: 0.19998100699035673   \n21     m: 0.9151709401709403 std: 0.02856862378351845   \n23     m: 0.9444949494949496 std: 0.04164152899506982   \n25   m: 0.47716293368467283 std: 0.004696804926703416   \n27     m: 0.9332491582491583 std: 0.04255264892173636   \n29  m: 0.11111111111111112 std: 1.3877787807814457...   \n31     m: 0.6693602693602694 std: 0.20784967494940076   \n33     m: 0.9307840307840308 std: 0.03813348030226439   \n35     m: 0.9444949494949496 std: 0.04164152899506982   \n37   m: 0.47716293368467283 std: 0.004696804926703416   \n39     m: 0.9332491582491583 std: 0.04255264892173636   \n41  m: 0.11111111111111112 std: 1.3877787807814457...   \n43     m: 0.6693602693602694 std: 0.20784967494940076   \n45     m: 0.9307840307840308 std: 0.03813348030226439   \n47     m: 0.9444949494949496 std: 0.04164152899506982   \n49   m: 0.47716293368467283 std: 0.004696804926703416   \n51     m: 0.9332491582491583 std: 0.04255264892173636   \n53  m: 0.11111111111111112 std: 1.3877787807814457...   \n55     m: 0.6693602693602694 std: 0.20784967494940076   \n\n                                             recall  \\\n1                  m: 0.96 std: 0.03887301263230201   \n3   m: 0.9733333333333334 std: 0.053333333333333365   \n5    m: 0.9466666666666667 std: 0.04521553322083516   \n13    m: 0.9533333333333334 std: 0.0339934634239519   \n17                 m: 0.74 std: 0.10413666234542203   \n21   m: 0.8799999999999999 std: 0.05416025603090637   \n23  m: 0.9400000000000001 std: 0.044221663871405366   \n25  m: 0.5599999999999999 std: 0.024944382578492935   \n27  m: 0.9266666666666665 std: 0.044221663871405345   \n29                   m: 0.3333333333333333 std: 0.0   \n31   m: 0.7666666666666666 std: 0.12292725943057183   \n33    m: 0.9199999999999999 std: 0.0452155332208351   \n35  m: 0.9400000000000001 std: 0.044221663871405366   \n37  m: 0.5599999999999999 std: 0.024944382578492935   \n39  m: 0.9266666666666665 std: 0.044221663871405345   \n41                   m: 0.3333333333333333 std: 0.0   \n43   m: 0.7666666666666666 std: 0.12292725943057183   \n45    m: 0.9199999999999999 std: 0.0452155332208351   \n47  m: 0.9400000000000001 std: 0.044221663871405366   \n49  m: 0.5599999999999999 std: 0.024944382578492935   \n51  m: 0.9266666666666665 std: 0.044221663871405345   \n53                   m: 0.3333333333333333 std: 0.0   \n55   m: 0.7666666666666666 std: 0.12292725943057183   \n\n                                        time training  \\\n1   total: 0.000997304916381836 values: [0.       ...   \n3                 total: 0.0 values: [0. 0. 0. 0. 0.]   \n5                 total: 0.0 values: [0. 0. 0. 0. 0.]   \n13  total: 0.002988100051879883 values: [0.       ...   \n17  total: 0.008975982666015625 values: [0.0019948...   \n21  total: 0.0029909610748291016 values: [0.000996...   \n23  total: 0.0039899349212646484 values: [0.000997...   \n25  total: 0.0009984970092773438 values: [0.      ...   \n27  total: 0.002992391586303711 values: [0.0009975...   \n29  total: 0.0029954910278320312 values: [0.001002...   \n31  total: 0.00498652458190918 values: [0.00099707...   \n33  total: 0.0029916763305664062 values: [0.000997...   \n35  total: 0.0009970664978027344 values: [0.      ...   \n37  total: 0.003989219665527344 values: [0.       ...   \n39  total: 0.002992391586303711 values: [0.       ...   \n41  total: 0.003988981246948242 values: [0.0009977...   \n43  total: 0.004987239837646484 values: [0.0009973...   \n45                total: 0.0 values: [0. 0. 0. 0. 0.]   \n47  total: 0.004975557327270508 values: [0.0009937...   \n49  total: 0.002956390380859375 values: [0.0009946...   \n51  total: 0.002009868621826172 values: [0.       ...   \n53  total: 0.0039103031158447266 values: [0.000969...   \n55  total: 0.0029611587524414062 values: [0.000965...   \n\n                                         time testing  \n1   total: 0.01296544075012207 values: [0.00299215...  \n3   total: 0.014959573745727539 values: [0.0029919...  \n5   total: 0.00997304916381836 values: [0.00199437...  \n13  total: 0.005987405776977539 values: [0.0009973...  \n17  total: 0.004987478256225586 values: [0.0009987...  \n21  total: 0.006982088088989258 values: [0.0009975...  \n23  total: 0.005985736846923828 values: [0.0009982...  \n25  total: 0.008977174758911133 values: [0.0019943...  \n27  total: 0.006968021392822266 values: [0.0009968...  \n29  total: 0.006973743438720703 values: [0.0009920...  \n31  total: 0.004986286163330078 values: [0.0009973...  \n33  total: 0.004986763000488281 values: [0.0009973...  \n35  total: 0.004986763000488281 values: [0.0009970...  \n37  total: 0.00498652458190918 values: [0.00099754...  \n39  total: 0.004985809326171875 values: [0.0009970...  \n41  total: 0.005984306335449219 values: [0.0009973...  \n43  total: 0.004987478256225586 values: [0.0009975...  \n45  total: 0.010005712509155273 values: [0.0019946...  \n47  total: 0.004998445510864258 values: [0.0009985...  \n49  total: 0.007015705108642578 values: [0.0009989...  \n51  total: 0.008897542953491211 values: [0.0009658...  \n53  total: 0.007031679153442383 values: [0.0020077...  \n55  total: 0.0050389766693115234 values: [0.001024...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.96 std: 0.038873012632301994</td>\n      <td>m: 0.9610774410774411 std: 0.03826764858710283</td>\n      <td>m: 0.96 std: 0.03887301263230201</td>\n      <td>total: 0.000997304916381836 values: [0.       ...</td>\n      <td>total: 0.01296544075012207 values: [0.00299215...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.05333333333333332</td>\n      <td>m: 0.975 std: 0.049999999999999996</td>\n      <td>m: 0.9733333333333334 std: 0.053333333333333365</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.014959573745727539 values: [0.0029919...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083511</td>\n      <td>m: 0.9517676767676768 std: 0.042228383872089235</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083516</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.00997304916381836 values: [0.00199437...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9533333333333334 std: 0.03399346342395189</td>\n      <td>m: 0.9550168350168351 std: 0.03375719358407477</td>\n      <td>m: 0.9533333333333334 std: 0.0339934634239519</td>\n      <td>total: 0.002988100051879883 values: [0.       ...</td>\n      <td>total: 0.005987405776977539 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.74 std: 0.10413666234542207</td>\n      <td>m: 0.6742889463477699 std: 0.19998100699035673</td>\n      <td>m: 0.74 std: 0.10413666234542203</td>\n      <td>total: 0.008975982666015625 values: [0.0019948...</td>\n      <td>total: 0.004987478256225586 values: [0.0009987...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8800000000000001 std: 0.05416025603090639</td>\n      <td>m: 0.9151709401709403 std: 0.02856862378351845</td>\n      <td>m: 0.8799999999999999 std: 0.05416025603090637</td>\n      <td>total: 0.0029909610748291016 values: [0.000996...</td>\n      <td>total: 0.006982088088989258 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.0039899349212646484 values: [0.000997...</td>\n      <td>total: 0.005985736846923828 values: [0.0009982...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0009984970092773438 values: [0.      ...</td>\n      <td>total: 0.008977174758911133 values: [0.0019943...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002992391586303711 values: [0.0009975...</td>\n      <td>total: 0.006968021392822266 values: [0.0009968...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0029954910278320312 values: [0.001002...</td>\n      <td>total: 0.006973743438720703 values: [0.0009920...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.00498652458190918 values: [0.00099707...</td>\n      <td>total: 0.004986286163330078 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0029916763305664062 values: [0.000997...</td>\n      <td>total: 0.004986763000488281 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.0009970664978027344 values: [0.      ...</td>\n      <td>total: 0.004986763000488281 values: [0.0009970...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.003989219665527344 values: [0.       ...</td>\n      <td>total: 0.00498652458190918 values: [0.00099754...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002992391586303711 values: [0.       ...</td>\n      <td>total: 0.004985809326171875 values: [0.0009970...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003988981246948242 values: [0.0009977...</td>\n      <td>total: 0.005984306335449219 values: [0.0009973...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.004987239837646484 values: [0.0009973...</td>\n      <td>total: 0.004987478256225586 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0 values: [0. 0. 0. 0. 0.]</td>\n      <td>total: 0.010005712509155273 values: [0.0019946...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.004975557327270508 values: [0.0009937...</td>\n      <td>total: 0.004998445510864258 values: [0.0009985...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.002956390380859375 values: [0.0009946...</td>\n      <td>total: 0.007015705108642578 values: [0.0009989...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.002009868621826172 values: [0.       ...</td>\n      <td>total: 0.008897542953491211 values: [0.0009658...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0039103031158447266 values: [0.000969...</td>\n      <td>total: 0.007031679153442383 values: [0.0020077...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0029611587524414062 values: [0.000965...</td>\n      <td>total: 0.0050389766693115234 values: [0.001024...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='k-fold')])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Despite the heterogenous approaches used, acccuracy, precision and recall were good across most approaches with the notable exception of the Perceptron.\n",
    "\n",
    "The data set may hence be prone to ceiling effects for measuring effectiveness for such numerical categorization tasks.\n",
    "\n",
    "### Efficiency\n",
    "In the datasets used as well as in the approaches applied, the training and testing time measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handwritten Numbers Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split  accuracy  \\\n6   digits                       kNN               n=5  holdout  0.983165   \n8   digits                       kNN              n=10  holdout  0.976431   \n10  digits                       kNN              n=20  holdout  0.961279   \n14  digits                     bayes              none  holdout  0.833333   \n18  digits                perceptron              none  holdout  0.939394   \n56  digits  Decision Tree Classifier    (5, 2, random)  holdout  0.673401   \n58  digits  Decision Tree Classifier      (5, 2, best)  holdout    0.6633   \n60  digits  Decision Tree Classifier   (5, 20, random)  holdout  0.643098   \n62  digits  Decision Tree Classifier     (5, 20, best)  holdout  0.658249   \n64  digits  Decision Tree Classifier   (5, 40, random)  holdout  0.624579   \n66  digits  Decision Tree Classifier     (5, 40, best)  holdout  0.607744   \n68  digits  Decision Tree Classifier   (10, 2, random)  holdout  0.821549   \n70  digits  Decision Tree Classifier     (10, 2, best)  holdout  0.833333   \n72  digits  Decision Tree Classifier  (10, 20, random)  holdout  0.742424   \n74  digits  Decision Tree Classifier    (10, 20, best)  holdout  0.794613   \n76  digits  Decision Tree Classifier  (10, 40, random)  holdout  0.621212   \n78  digits  Decision Tree Classifier    (10, 40, best)  holdout  0.734007   \n80  digits  Decision Tree Classifier   (15, 2, random)  holdout  0.826599   \n82  digits  Decision Tree Classifier     (15, 2, best)  holdout   0.83165   \n84  digits  Decision Tree Classifier  (15, 20, random)  holdout  0.742424   \n86  digits  Decision Tree Classifier    (15, 20, best)  holdout  0.794613   \n88  digits  Decision Tree Classifier  (15, 40, random)  holdout  0.621212   \n90  digits  Decision Tree Classifier    (15, 40, best)  holdout  0.734007   \n\n   precision    recall time training time testing  \n6   0.983364  0.983174     0.0159564     0.106744  \n8   0.976702  0.976281     0.0159283    0.0917542  \n10  0.962286  0.961089     0.0259006     0.109705  \n14  0.850641  0.833908    0.00299025  0.000997305  \n18   0.94141   0.93962     0.0239413  0.000996351  \n56  0.717454  0.677103    0.00299382            0  \n58  0.746121  0.663671    0.00900841            0  \n60  0.637573  0.641345    0.00399446  0.000993967  \n62  0.720075  0.657125    0.00897002  0.000971794  \n64  0.595066  0.623683    0.00299263            0  \n66   0.59806  0.604756    0.00797749  0.000996828  \n68  0.827151  0.822762    0.00598502  0.000996113  \n70   0.84214  0.836688     0.0139637            0  \n72  0.749126  0.743035    0.00398827            0  \n74   0.80054  0.797709    0.00997877  0.000995874  \n76  0.649174  0.622869    0.00299239  0.000998497  \n78  0.764335   0.73374     0.0109711  0.000998259  \n80  0.832276  0.828587    0.00498438            0  \n82  0.839983  0.835681     0.0149601            0  \n84  0.749126  0.743035    0.00598431            0  \n86   0.80054  0.797709     0.0119667            0  \n88  0.649174  0.622869    0.00299263  0.000997782  \n90  0.764335   0.73374    0.00997281            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.983165</td>\n      <td>0.983364</td>\n      <td>0.983174</td>\n      <td>0.0159564</td>\n      <td>0.106744</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.976431</td>\n      <td>0.976702</td>\n      <td>0.976281</td>\n      <td>0.0159283</td>\n      <td>0.0917542</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.961279</td>\n      <td>0.962286</td>\n      <td>0.961089</td>\n      <td>0.0259006</td>\n      <td>0.109705</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.850641</td>\n      <td>0.833908</td>\n      <td>0.00299025</td>\n      <td>0.000997305</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.939394</td>\n      <td>0.94141</td>\n      <td>0.93962</td>\n      <td>0.0239413</td>\n      <td>0.000996351</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.673401</td>\n      <td>0.717454</td>\n      <td>0.677103</td>\n      <td>0.00299382</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.6633</td>\n      <td>0.746121</td>\n      <td>0.663671</td>\n      <td>0.00900841</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.643098</td>\n      <td>0.637573</td>\n      <td>0.641345</td>\n      <td>0.00399446</td>\n      <td>0.000993967</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.658249</td>\n      <td>0.720075</td>\n      <td>0.657125</td>\n      <td>0.00897002</td>\n      <td>0.000971794</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.624579</td>\n      <td>0.595066</td>\n      <td>0.623683</td>\n      <td>0.00299263</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.607744</td>\n      <td>0.59806</td>\n      <td>0.604756</td>\n      <td>0.00797749</td>\n      <td>0.000996828</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.821549</td>\n      <td>0.827151</td>\n      <td>0.822762</td>\n      <td>0.00598502</td>\n      <td>0.000996113</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.84214</td>\n      <td>0.836688</td>\n      <td>0.0139637</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00398827</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00997877</td>\n      <td>0.000995874</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299239</td>\n      <td>0.000998497</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.0109711</td>\n      <td>0.000998259</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.826599</td>\n      <td>0.832276</td>\n      <td>0.828587</td>\n      <td>0.00498438</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.83165</td>\n      <td>0.839983</td>\n      <td>0.835681</td>\n      <td>0.0149601</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00598431</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.0119667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299263</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00997281</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n7   digits                       kNN               n=5  k-fold   \n9   digits                       kNN              n=10  k-fold   \n11  digits                       kNN              n=20  k-fold   \n15  digits                     bayes              none  k-fold   \n19  digits                perceptron              none  k-fold   \n57  digits  Decision Tree Classifier    (5, 2, random)  k-fold   \n59  digits  Decision Tree Classifier      (5, 2, best)  k-fold   \n61  digits  Decision Tree Classifier   (5, 20, random)  k-fold   \n63  digits  Decision Tree Classifier     (5, 20, best)  k-fold   \n65  digits  Decision Tree Classifier   (5, 40, random)  k-fold   \n67  digits  Decision Tree Classifier     (5, 40, best)  k-fold   \n69  digits  Decision Tree Classifier   (10, 2, random)  k-fold   \n71  digits  Decision Tree Classifier     (10, 2, best)  k-fold   \n73  digits  Decision Tree Classifier  (10, 20, random)  k-fold   \n75  digits  Decision Tree Classifier    (10, 20, best)  k-fold   \n77  digits  Decision Tree Classifier  (10, 40, random)  k-fold   \n79  digits  Decision Tree Classifier    (10, 40, best)  k-fold   \n81  digits  Decision Tree Classifier   (15, 2, random)  k-fold   \n83  digits  Decision Tree Classifier     (15, 2, best)  k-fold   \n85  digits  Decision Tree Classifier  (15, 20, random)  k-fold   \n87  digits  Decision Tree Classifier    (15, 20, best)  k-fold   \n89  digits  Decision Tree Classifier  (15, 40, random)  k-fold   \n91  digits  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n7   m: 0.9883163107397092 std: 0.005388572629804117   \n9   m: 0.9805277004023523 std: 0.007241231361602902   \n11  m: 0.9705060352831941 std: 0.006724967766856801   \n15  m: 0.8324945837202105 std: 0.009286635323422067   \n19  m: 0.9410229031259671 std: 0.015849668296257387   \n57     m: 0.682799442896936 std: 0.0225789955736832   \n59  m: 0.6521990095945527 std: 0.029293764851288196   \n61  m: 0.6750278551532034 std: 0.040755563742608684   \n63   m: 0.642189724543485 std: 0.026859596447899876   \n65   m: 0.6282559579077684 std: 0.04962782791262363   \n67  m: 0.6271649644073042 std: 0.022340010709646117   \n69  m: 0.8492169606932837 std: 0.024701250873822116   \n71  m: 0.8497415660786135 std: 0.016289255420700997   \n73  m: 0.7334292788610337 std: 0.020905478914734647   \n75   m: 0.7879712163416899 std: 0.01638106112774851   \n77  m: 0.6956360259981429 std: 0.030311998503533933   \n79   m: 0.7551593933766635 std: 0.02118747834909684   \n81    m: 0.8480857319715259 std: 0.0160451900425344   \n83  m: 0.8503002166511916 std: 0.009784061096593345   \n85  m: 0.7334292788610337 std: 0.020905478914734647   \n87   m: 0.7879712163416899 std: 0.01638106112774851   \n89  m: 0.6956360259981429 std: 0.030311998503533933   \n91   m: 0.7551593933766635 std: 0.02118747834909684   \n\n                                          precision  \\\n7   m: 0.9887866449971712 std: 0.005222598238459717   \n9    m: 0.9816830468409415 std: 0.00662931853158472   \n11  m: 0.9717214434156635 std: 0.006292571449491544   \n15  m: 0.8598088622118409 std: 0.015147678383072103   \n19   m: 0.9472330796425998 std: 0.01371753706347739   \n57   m: 0.717660567564935 std: 0.026132446284686445   \n59   m: 0.7298174310895975 std: 0.01717008365700091   \n61  m: 0.6950497115958991 std: 0.061857032803490745   \n63    m: 0.703735266738326 std: 0.01501969790860612   \n65   m: 0.6253692157304211 std: 0.05839129334704999   \n67   m: 0.6660513441822741 std: 0.02980445680574132   \n69  m: 0.8535964619626707 std: 0.024247845316340284   \n71  m: 0.8559045305923447 std: 0.016949978229067093   \n73   m: 0.7394966477817702 std: 0.02134785363906439   \n75  m: 0.7966323249656977 std: 0.019183878519583475   \n77   m: 0.7156065230428587 std: 0.03517987997097763   \n79  m: 0.7708872928512271 std: 0.018327983630086836   \n81  m: 0.8518270691602231 std: 0.014618370518263432   \n83  m: 0.8570756527976207 std: 0.010812556072823007   \n85   m: 0.7394966477817702 std: 0.02134785363906439   \n87  m: 0.7966323249656977 std: 0.019183878519583475   \n89   m: 0.7156065230428587 std: 0.03517987997097763   \n91  m: 0.7708872928512271 std: 0.018327983630086836   \n\n                                              recall  \\\n7   m: 0.9882804905746081 std: 0.0053145264097686756   \n9     m: 0.9804048249930603 std: 0.00715395193374626   \n11    m: 0.9702434451257981 std: 0.00681107277803136   \n15   m: 0.8325454614278144 std: 0.009764788694682724   \n19   m: 0.9410189264895147 std: 0.015777826142176866   \n57   m: 0.6822451106568753 std: 0.022306835943359964   \n59   m: 0.6520541549953315 std: 0.028721061472361847   \n61     m: 0.674860019683549 std: 0.04133979548873456   \n63   m: 0.6420215509627274 std: 0.026807715646732715   \n65   m: 0.6283112019582608 std: 0.050742761166004666   \n67   m: 0.6270297019708784 std: 0.022343553593636677   \n69    m: 0.848803896333308 std: 0.024983989383474584   \n71   m: 0.8496446109975521 std: 0.016132101050840803   \n73    m: 0.7331400055517703 std: 0.02089872408546371   \n75     m: 0.7882291114644057 std: 0.0162673398542481   \n77    m: 0.6946652282534636 std: 0.03080685318605075   \n79    m: 0.754918641330406 std: 0.021705452983571242   \n81    m: 0.847657531481061 std: 0.016500416901784897   \n83   m: 0.8501242334771746 std: 0.009676746964727485   \n85    m: 0.7331400055517703 std: 0.02089872408546371   \n87     m: 0.7882291114644057 std: 0.0162673398542481   \n89    m: 0.6946652282534636 std: 0.03080685318605075   \n91    m: 0.754918641330406 std: 0.021705452983571242   \n\n                                        time training  \\\n7   total: 0.10268950462341309 values: [0.02191734...   \n9   total: 0.10272455215454102 values: [0.01894951...   \n11  total: 0.11178374290466309 values: [0.02097678...   \n15  total: 0.012965917587280273 values: [0.0029923...   \n19  total: 0.15159392356872559 values: [0.02991819...   \n57  total: 0.02091217041015625 values: [0.00398803...   \n59  total: 0.05185675621032715 values: [0.00997257...   \n61  total: 0.024979591369628906 values: [0.0049858...   \n63  total: 0.06183505058288574 values: [0.01296616...   \n65  total: 0.022940874099731445 values: [0.0049877...   \n67  total: 0.054849863052368164 values: [0.0119662...   \n69  total: 0.035906076431274414 values: [0.0079789...   \n71  total: 0.08380770683288574 values: [0.01895046...   \n73  total: 0.024934053421020508 values: [0.004987 ...   \n75  total: 0.0777595043182373 values: [0.0149591  ...   \n77  total: 0.026928424835205078 values: [0.0059833...   \n79  total: 0.0688161849975586 values: [0.01396251 ...   \n81  total: 0.03790116310119629 values: [0.00698161...   \n83  total: 0.10072803497314453 values: [0.01894808...   \n85  total: 0.02891850471496582 values: [0.00498486...   \n87  total: 0.07380175590515137 values: [0.01396275...   \n89  total: 0.025930166244506836 values: [0.0049872...   \n91  total: 0.06183338165283203 values: [0.01196599...   \n\n                                         time testing  \n7   total: 0.3243260383605957 values: [0.06796765 ...  \n9   total: 0.3530890941619873 values: [0.06386065 ...  \n11  total: 0.38193178176879883 values: [0.06678843...  \n15  total: 0.011965274810791016 values: [0.0019936...  \n19  total: 0.008939266204833984 values: [0.0009942...  \n57  total: 0.007982969284057617 values: [0.0019989...  \n59  total: 0.009945154190063477 values: [0.0019941...  \n61  total: 0.010895013809204102 values: [0.001966 ...  \n63  total: 0.008976459503173828 values: [0.0009968...  \n65  total: 0.011968612670898438 values: [0.0029923...  \n67  total: 0.00897359848022461 values: [0.00099683...  \n69  total: 0.011968135833740234 values: [0.0029931...  \n71  total: 0.009973764419555664 values: [0.0019934...  \n73  total: 0.00797724723815918 values: [0.00199437...  \n75  total: 0.011968374252319336 values: [0.0019946...  \n77  total: 0.009973287582397461 values: [0.0019948...  \n79  total: 0.009972810745239258 values: [0.0019938...  \n81  total: 0.010967731475830078 values: [0.0019941...  \n83  total: 0.010973691940307617 values: [0.0019955...  \n85  total: 0.010972976684570312 values: [0.0019950...  \n87  total: 0.011967658996582031 values: [0.0039889...  \n89  total: 0.009973287582397461 values: [0.0019929...  \n91  total: 0.00997304916381836 values: [0.00199509...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.9883163107397092 std: 0.005388572629804117</td>\n      <td>m: 0.9887866449971712 std: 0.005222598238459717</td>\n      <td>m: 0.9882804905746081 std: 0.0053145264097686756</td>\n      <td>total: 0.10268950462341309 values: [0.02191734...</td>\n      <td>total: 0.3243260383605957 values: [0.06796765 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9805277004023523 std: 0.007241231361602902</td>\n      <td>m: 0.9816830468409415 std: 0.00662931853158472</td>\n      <td>m: 0.9804048249930603 std: 0.00715395193374626</td>\n      <td>total: 0.10272455215454102 values: [0.01894951...</td>\n      <td>total: 0.3530890941619873 values: [0.06386065 ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9705060352831941 std: 0.006724967766856801</td>\n      <td>m: 0.9717214434156635 std: 0.006292571449491544</td>\n      <td>m: 0.9702434451257981 std: 0.00681107277803136</td>\n      <td>total: 0.11178374290466309 values: [0.02097678...</td>\n      <td>total: 0.38193178176879883 values: [0.06678843...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.8324945837202105 std: 0.009286635323422067</td>\n      <td>m: 0.8598088622118409 std: 0.015147678383072103</td>\n      <td>m: 0.8325454614278144 std: 0.009764788694682724</td>\n      <td>total: 0.012965917587280273 values: [0.0029923...</td>\n      <td>total: 0.011965274810791016 values: [0.0019936...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9410229031259671 std: 0.015849668296257387</td>\n      <td>m: 0.9472330796425998 std: 0.01371753706347739</td>\n      <td>m: 0.9410189264895147 std: 0.015777826142176866</td>\n      <td>total: 0.15159392356872559 values: [0.02991819...</td>\n      <td>total: 0.008939266204833984 values: [0.0009942...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.682799442896936 std: 0.0225789955736832</td>\n      <td>m: 0.717660567564935 std: 0.026132446284686445</td>\n      <td>m: 0.6822451106568753 std: 0.022306835943359964</td>\n      <td>total: 0.02091217041015625 values: [0.00398803...</td>\n      <td>total: 0.007982969284057617 values: [0.0019989...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6521990095945527 std: 0.029293764851288196</td>\n      <td>m: 0.7298174310895975 std: 0.01717008365700091</td>\n      <td>m: 0.6520541549953315 std: 0.028721061472361847</td>\n      <td>total: 0.05185675621032715 values: [0.00997257...</td>\n      <td>total: 0.009945154190063477 values: [0.0019941...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6750278551532034 std: 0.040755563742608684</td>\n      <td>m: 0.6950497115958991 std: 0.061857032803490745</td>\n      <td>m: 0.674860019683549 std: 0.04133979548873456</td>\n      <td>total: 0.024979591369628906 values: [0.0049858...</td>\n      <td>total: 0.010895013809204102 values: [0.001966 ...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.642189724543485 std: 0.026859596447899876</td>\n      <td>m: 0.703735266738326 std: 0.01501969790860612</td>\n      <td>m: 0.6420215509627274 std: 0.026807715646732715</td>\n      <td>total: 0.06183505058288574 values: [0.01296616...</td>\n      <td>total: 0.008976459503173828 values: [0.0009968...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6282559579077684 std: 0.04962782791262363</td>\n      <td>m: 0.6253692157304211 std: 0.05839129334704999</td>\n      <td>m: 0.6283112019582608 std: 0.050742761166004666</td>\n      <td>total: 0.022940874099731445 values: [0.0049877...</td>\n      <td>total: 0.011968612670898438 values: [0.0029923...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6271649644073042 std: 0.022340010709646117</td>\n      <td>m: 0.6660513441822741 std: 0.02980445680574132</td>\n      <td>m: 0.6270297019708784 std: 0.022343553593636677</td>\n      <td>total: 0.054849863052368164 values: [0.0119662...</td>\n      <td>total: 0.00897359848022461 values: [0.00099683...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8492169606932837 std: 0.024701250873822116</td>\n      <td>m: 0.8535964619626707 std: 0.024247845316340284</td>\n      <td>m: 0.848803896333308 std: 0.024983989383474584</td>\n      <td>total: 0.035906076431274414 values: [0.0079789...</td>\n      <td>total: 0.011968135833740234 values: [0.0029931...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8497415660786135 std: 0.016289255420700997</td>\n      <td>m: 0.8559045305923447 std: 0.016949978229067093</td>\n      <td>m: 0.8496446109975521 std: 0.016132101050840803</td>\n      <td>total: 0.08380770683288574 values: [0.01895046...</td>\n      <td>total: 0.009973764419555664 values: [0.0019934...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.024934053421020508 values: [0.004987 ...</td>\n      <td>total: 0.00797724723815918 values: [0.00199437...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.0777595043182373 values: [0.0149591  ...</td>\n      <td>total: 0.011968374252319336 values: [0.0019946...</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.026928424835205078 values: [0.0059833...</td>\n      <td>total: 0.009973287582397461 values: [0.0019948...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.0688161849975586 values: [0.01396251 ...</td>\n      <td>total: 0.009972810745239258 values: [0.0019938...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8480857319715259 std: 0.0160451900425344</td>\n      <td>m: 0.8518270691602231 std: 0.014618370518263432</td>\n      <td>m: 0.847657531481061 std: 0.016500416901784897</td>\n      <td>total: 0.03790116310119629 values: [0.00698161...</td>\n      <td>total: 0.010967731475830078 values: [0.0019941...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8503002166511916 std: 0.009784061096593345</td>\n      <td>m: 0.8570756527976207 std: 0.010812556072823007</td>\n      <td>m: 0.8501242334771746 std: 0.009676746964727485</td>\n      <td>total: 0.10072803497314453 values: [0.01894808...</td>\n      <td>total: 0.010973691940307617 values: [0.0019955...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.02891850471496582 values: [0.00498486...</td>\n      <td>total: 0.010972976684570312 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.07380175590515137 values: [0.01396275...</td>\n      <td>total: 0.011967658996582031 values: [0.0039889...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.025930166244506836 values: [0.0049872...</td>\n      <td>total: 0.009973287582397461 values: [0.0019929...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.06183338165283203 values: [0.01196599...</td>\n      <td>total: 0.00997304916381836 values: [0.00199509...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Again,  acccuracy, precision and recall were good across all approaches.\n",
    "In this specific case, also the perceptron yielded notable better results.\n",
    "\n",
    "Again, the data set may  be prone to ceiling effects for measuring effectiveness for such image recognition tasks.\n",
    "\n",
    "### Efficiency\n",
    "Similar to the Iris dataset the training and testing time measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks.\n",
    "Larger and more complex datasets would yield more meaningful results in terms of efficiency."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}