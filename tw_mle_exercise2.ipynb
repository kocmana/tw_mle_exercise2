{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLE - Exercise 2 - Comparative Experimentation\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "## Assignment\n",
    "In this exercise, you shall experiment with a number of (simple) algorithms on several datasets. The aim is to get a feeling how well each of these algorithms works, and whether there are differences depending on the dataset.\n",
    "\n",
    "The datasets are\n",
    "* [Iris](https://archive.ics.uci.edu/ml/datasets/Iris), for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "* [Handwritten digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits), of which we only use the test set of 1797 instances; for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)\n",
    "* If you are a group of three (see below): [Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)); skip the ID field; in Python: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "\n",
    "The classifiers you shall use are\n",
    "* k-NN (with 3 different values for k)\n",
    "* Naive Bayes\n",
    "* Perceptron, and\n",
    "* Decision Trees with 3 different parameter settings (e.g. some pre-pruning setting, different split criterion, ...)\n",
    "\n",
    "For each dataset, you shall train and evaluate each classifier (with parameter variations), and then compute several evaluation metrics\n",
    "* Effectiveness: Accuracy, and 1 more of your choice (precision, recall, F1, ...\n",
    "* Efficiency: runtime for training & testing\n",
    "* As evaluation set splitting technique, you shall use once the holdout method with 2/3 training and the rest for testing, and once cross validation with 5 folds.\n",
    "\n",
    "You shall present these results in a tabular form, with one table for each dataset & splitting combination approach.\n",
    "\n",
    "Iris/5-folds | Accuracy | Precision| Training time | Testing time\n",
    "---|---|---|---|---|---\n",
    "k-NN (3-NN) | .85 | .82 | 0.1 sec | 27 sec\n",
    "Naive Bayes | .72 | .82 | 1 sec | 2 sec\n",
    "Decision Tree | .92 | .76 | 5 sec | 2 sec\n",
    "... | ... | ...| ... | ...\n",
    "\n",
    "Then describe the results, and analyse e.g.:\n",
    "* Which classifiers work best?\n",
    "* Are there differences between the datasets?\n",
    "* Are the differences in the efficiency measurements?\n",
    "* How is the runtime changing with the different data sets?\n",
    "* ...\n",
    "\n",
    "You can solve this exercise alone, or in a group of two students. If you form a group, you need to extend your scope, by\n",
    "* Adding a third dataset, namely breast cancer wisconsin\n",
    "* For k-NN, using 5 different values for k instead of 3, and use both weighted and uniform distance (i.e. a total of 10 combinations); for Decision Trees, also add 3 more parameter variations\n",
    "* Adding a third efficiency evaluation metric\n",
    "\n",
    "## Deliverables\n",
    "Your submission shall contain\n",
    "* The textual report\n",
    "* All code samples and\n",
    "* All data sets (if not already included in your software package, e.g. Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sources used\n",
    "* Scikit documentation\n",
    "* https://simonhessner.de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-multi-class-problem/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#General Imports\n",
    "import numpy as numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "#Global variables\n",
    "randomState=24  # change the state with the numeric parts of your matrikelnummer; if you are in a group, use the sume of the numeric parts\n",
    "                # se19m024\n",
    "averagingApproach = 'macro'\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro']\n",
    "zero_divisionApproach = 0\n",
    "number_of_folds = 5\n",
    "\n",
    "#Overall report\n",
    "ml_approaches = ['k-NN', 'bayes', 'perceptron', 'decision tree']\n",
    "resultColumns = ['dataset','approach','arguments','split','accuracy','precision','recall','time training', 'time testing']\n",
    "\n",
    "#Helper funcitons\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(numpy.average(results)) + \" std: \" + str(numpy.std(results)) # + \" values: \" + str(results)\n",
    "\n",
    "def parse_k_fold_timings(results):\n",
    "    return \"total: \" + str(numpy.sum(results)) + \" values: \" + str(results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn_results = []\n",
    "testvalues = [3,10,15]\n",
    "\n",
    "# parameters for k-NN\n",
    "n_neighbors = testvalues\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        # train the k-NN\n",
    "        classifier = neighbors.KNeighborsClassifier(n)\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0 )\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_precision_macro')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_recall_macro')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "knn_results_df = pd.DataFrame(knn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "The results below show extremely high accuracy for kNN both with N values of 3, 10 and 15."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris      kNN       n=3  holdout     0.94  0.941176  0.952381   \n2    iris      kNN      n=10  holdout     0.92  0.925926  0.936508   \n4    iris      kNN      n=15  holdout     0.92  0.925926  0.936508   \n\n  time training time testing  \n0             0    0.0029912  \n2    0.00100708   0.00198483  \n4   0.000997543   0.00199461  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>holdout</td>\n      <td>0.94</td>\n      <td>0.941176</td>\n      <td>0.952381</td>\n      <td>0</td>\n      <td>0.0029912</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0.00100708</td>\n      <td>0.00198483</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0.000997543</td>\n      <td>0.00199461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris      kNN       n=3  k-fold   \n3    iris      kNN      n=10  k-fold   \n5    iris      kNN      n=15  k-fold   \n\n                                          accuracy  \\\n1  m: 0.9600000000000002 std: 0.024944382578492935   \n3   m: 0.9733333333333334 std: 0.05333333333333332   \n5  m: 0.9733333333333334 std: 0.038873012632301994   \n\n                                         precision  \\\n1   m: 0.9612121212121212 std: 0.02530983396099532   \n3               m: 0.975 std: 0.049999999999999996   \n5  m: 0.9744107744107744 std: 0.037890383559960134   \n\n                                            recall  \\\n1                m: 0.96 std: 0.024944382578492984   \n3  m: 0.9733333333333334 std: 0.053333333333333365   \n5  m: 0.9733333333333334 std: 0.038873012632301994   \n\n                                       time training  \\\n1  total: 0.0029926300048828125 values: [0.000997...   \n3  total: 0.0019941329956054688 values: [0.      ...   \n5  total: 0.0019826889038085938 values: [0.000985...   \n\n                                        time testing  \n1  total: 0.013962507247924805 values: [0.0029921...  \n3  total: 0.012965917587280273 values: [0.0029921...  \n5  total: 0.014960050582885742 values: [0.0029919...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>k-fold</td>\n      <td>m: 0.9600000000000002 std: 0.024944382578492935</td>\n      <td>m: 0.9612121212121212 std: 0.02530983396099532</td>\n      <td>m: 0.96 std: 0.024944382578492984</td>\n      <td>total: 0.0029926300048828125 values: [0.000997...</td>\n      <td>total: 0.013962507247924805 values: [0.0029921...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.05333333333333332</td>\n      <td>m: 0.975 std: 0.049999999999999996</td>\n      <td>m: 0.9733333333333334 std: 0.053333333333333365</td>\n      <td>total: 0.0019941329956054688 values: [0.      ...</td>\n      <td>total: 0.012965917587280273 values: [0.0029921...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.038873012632301994</td>\n      <td>m: 0.9744107744107744 std: 0.037890383559960134</td>\n      <td>m: 0.9733333333333334 std: 0.038873012632301994</td>\n      <td>total: 0.0019826889038085938 values: [0.000985...</td>\n      <td>total: 0.014960050582885742 values: [0.0029919...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='holdout')])\n",
    "display(knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset approach arguments    split  accuracy precision    recall  \\\n6   digits      kNN       n=3  holdout  0.991582   0.99161  0.991301   \n8   digits      kNN      n=10  holdout  0.976431  0.976702  0.976281   \n10  digits      kNN      n=15  holdout  0.969697  0.969727  0.969164   \n\n   time training time testing  \n6      0.0179558    0.0987611  \n8       0.017952     0.102726  \n10     0.0159569     0.092752  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>holdout</td>\n      <td>0.991582</td>\n      <td>0.99161</td>\n      <td>0.991301</td>\n      <td>0.0179558</td>\n      <td>0.0987611</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.976431</td>\n      <td>0.976702</td>\n      <td>0.976281</td>\n      <td>0.017952</td>\n      <td>0.102726</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>holdout</td>\n      <td>0.969697</td>\n      <td>0.969727</td>\n      <td>0.969164</td>\n      <td>0.0159569</td>\n      <td>0.092752</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset approach arguments   split  \\\n7   digits      kNN       n=3  k-fold   \n9   digits      kNN      n=10  k-fold   \n11  digits      kNN      n=15  k-fold   \n\n                                           accuracy  \\\n7   m: 0.9883209532652429 std: 0.007323832501573226   \n9   m: 0.9805277004023523 std: 0.007241231361602902   \n11  m: 0.9771850820179511 std: 0.008687630086523833   \n\n                                          precision  \\\n7    m: 0.9888385412595939 std: 0.00712739147876576   \n9    m: 0.9816830468409415 std: 0.00662931853158472   \n11  m: 0.9786983227511679 std: 0.007575736564379982   \n\n                                             recall  \\\n7   m: 0.9882972972972972 std: 0.007208664307978579   \n9    m: 0.9804048249930603 std: 0.00715395193374626   \n11  m: 0.9770371716254068 std: 0.008674693211716449   \n\n                                        time training  \\\n7   total: 0.10275459289550781 values: [0.02094388...   \n9   total: 0.10275840759277344 values: [0.02194023...   \n11  total: 0.09970474243164062 values: [0.01994562...   \n\n                                         time testing  \n7   total: 0.3311154842376709 values: [0.06682134 ...  \n9   total: 0.337064266204834 values: [0.07081056 0...  \n11  total: 0.32419276237487793 values: [0.06382966...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>k-fold</td>\n      <td>m: 0.9883209532652429 std: 0.007323832501573226</td>\n      <td>m: 0.9888385412595939 std: 0.00712739147876576</td>\n      <td>m: 0.9882972972972972 std: 0.007208664307978579</td>\n      <td>total: 0.10275459289550781 values: [0.02094388...</td>\n      <td>total: 0.3311154842376709 values: [0.06682134 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9805277004023523 std: 0.007241231361602902</td>\n      <td>m: 0.9816830468409415 std: 0.00662931853158472</td>\n      <td>m: 0.9804048249930603 std: 0.00715395193374626</td>\n      <td>total: 0.10275840759277344 values: [0.02194023...</td>\n      <td>total: 0.337064266204834 values: [0.07081056 0...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>k-fold</td>\n      <td>m: 0.9771850820179511 std: 0.008687630086523833</td>\n      <td>m: 0.9786983227511679 std: 0.007575736564379982</td>\n      <td>m: 0.9770371716254068 std: 0.008674693211716449</td>\n      <td>total: 0.09970474243164062 values: [0.01994562...</td>\n      <td>total: 0.32419276237487793 values: [0.06382966...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='holdout')])\n",
    "display(knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "The results indicate a best fit of a solution for n=9."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "bayes_results = []\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = naive_bayes.GaussianNB()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                            scoring = scoring,\n",
    "                            cv = number_of_folds,\n",
    "                            error_score = 0)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_precision_macro')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_recall_macro')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "bayes_results_df = pd.DataFrame(bayes_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris    bayes      none  holdout      0.9   0.90305  0.912698   \n\n  time training time testing  \n0   0.000997305            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris    bayes      none  k-fold   \n\n                                         accuracy  \\\n1  m: 0.9533333333333334 std: 0.03399346342395189   \n\n                                        precision  \\\n1  m: 0.9550168350168351 std: 0.03375719358407477   \n\n                                          recall  \\\n1  m: 0.9533333333333334 std: 0.0339934634239519   \n\n                                       time training  \\\n1  total: 0.0029859542846679688 values: [0.000996...   \n\n                                        time testing  \n1  total: 0.005992412567138672 values: [0.0009999...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9533333333333334 std: 0.03399346342395189</td>\n      <td>m: 0.9550168350168351 std: 0.03375719358407477</td>\n      <td>m: 0.9533333333333334 std: 0.0339934634239519</td>\n      <td>total: 0.0029859542846679688 values: [0.000996...</td>\n      <td>total: 0.005992412567138672 values: [0.0009999...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='holdout')])\n",
    "display(bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset approach arguments    split  accuracy precision    recall  \\\n2  digits    bayes      none  holdout  0.833333  0.850641  0.833908   \n\n  time training time testing  \n2    0.00199437    0.0019691  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.850641</td>\n      <td>0.833908</td>\n      <td>0.00199437</td>\n      <td>0.0019691</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n3  digits    bayes      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.8324945837202105 std: 0.009286635323422067   \n\n                                         precision  \\\n3  m: 0.8598088622118409 std: 0.015147678383072103   \n\n                                            recall  \\\n3  m: 0.8325454614278144 std: 0.009764788694682724   \n\n                                       time training  \\\n3  total: 0.01199197769165039 values: [0.00199556...   \n\n                                        time testing  \n3  total: 0.01297307014465332 values: [0.00299144...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.8324945837202105 std: 0.009286635323422067</td>\n      <td>m: 0.8598088622118409 std: 0.015147678383072103</td>\n      <td>m: 0.8325454614278144 std: 0.009764788694682724</td>\n      <td>total: 0.01199197769165039 values: [0.00199556...</td>\n      <td>total: 0.01297307014465332 values: [0.00299144...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='holdout')])\n",
    "display(bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Analysis using Bayes on the *Iris* dataset show good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "* Analysis using Bayes on the *Digit Dataset* show still good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "\n",
    "However, compared to k NN, the results for this data set are significantly lower for Bayes. While this was similar for the Iris dataset, with lower accuracy for bayes than for the k-nn, the difference was not similarly strong.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "perceptron_results = []\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = linear_model.Perceptron()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                            scoring = scoring,\n",
    "                            cv = number_of_folds,\n",
    "                            error_score = 0)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_precision_macro')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_recall_macro')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "perceptron_results_df = pd.DataFrame(perceptron_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split accuracy precision recall  \\\n0    iris  perceptron      none  holdout     0.34  0.432624    0.4   \n\n  time training time testing  \n0    0.00202298            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.34</td>\n      <td>0.432624</td>\n      <td>0.4</td>\n      <td>0.00202298</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split                          accuracy  \\\n1    iris  perceptron      none  k-fold  m: 0.74 std: 0.10413666234542207   \n\n                                        precision  \\\n1  m: 0.6742889463477699 std: 0.19998100699035673   \n\n                             recall  \\\n1  m: 0.74 std: 0.10413666234542203   \n\n                                       time training  \\\n1  total: 0.009000301361083984 values: [0.0019946...   \n\n                                        time testing  \n1  total: 0.008951425552368164 values: [0.0029592...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.74 std: 0.10413666234542207</td>\n      <td>m: 0.6742889463477699 std: 0.19998100699035673</td>\n      <td>m: 0.74 std: 0.10413666234542203</td>\n      <td>total: 0.009000301361083984 values: [0.0019946...</td>\n      <td>total: 0.008951425552368164 values: [0.0029592...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='holdout')])\n",
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split  accuracy precision   recall  \\\n2  digits  perceptron      none  holdout  0.939394   0.94141  0.93962   \n\n  time training time testing  \n2     0.0239067            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.939394</td>\n      <td>0.94141</td>\n      <td>0.93962</td>\n      <td>0.0239067</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split  \\\n3  digits  perceptron      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.9410229031259671 std: 0.015849668296257387   \n\n                                        precision  \\\n3  m: 0.9472330796425998 std: 0.01371753706347739   \n\n                                            recall  \\\n3  m: 0.9410189264895147 std: 0.015777826142176866   \n\n                                       time training  \\\n3  total: 0.13663363456726074 values: [0.02892208...   \n\n                                        time testing  \n3  total: 0.00698399543762207 values: [0.00099802...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9410229031259671 std: 0.015849668296257387</td>\n      <td>m: 0.9472330796425998 std: 0.01371753706347739</td>\n      <td>m: 0.9410189264895147 std: 0.015777826142176866</td>\n      <td>total: 0.13663363456726074 values: [0.02892208...</td>\n      <td>total: 0.00698399543762207 values: [0.00099802...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='holdout')])\n",
    "display(perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Analysis using the Perceptron approach on the *Iris dataset* show low values for accuracy, precision and recall with extremely low training and testing time.\n",
    "Compared to both Bayes and k NN, the results for this data set are significantly lower.\n",
    "* Analysis using the Perceptron approach on the *Digits dataset* show very good values for accuracy, precision and recall with extremely low training and testing time.\n",
    "Both Bayes and kNN yielded comparable results. The difference between the Digit and Iris dataset show Perceptron's high susceptibility to the data it is used for."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\informatik\\tw_mle_exercise2\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "decision_tree_results = []\n",
    "\n",
    "# Parameters for the decision tree\n",
    "max_depth_arguments = [5,10,15]\n",
    "min_samples_leaf_arguments = [2,20,40]\n",
    "splitting_approaches_arguments = ['random', 'best']\n",
    "argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                        min_samples_leaf_arguments,\n",
    "                                        splitting_approaches_arguments))\n",
    "\n",
    "for dataset in [('iris', datasets.load_iris()),('digits', datasets.load_digits())]:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "        splitting_approach = argumentTuple[2]\n",
    "\n",
    "        # train the k-NN\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = splitting_approach)\n",
    "\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': argumentTuple,\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': argumentTuple,\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_precision_macro')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_recall_macro')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "decision_tree_results_df = pd.DataFrame(decision_tree_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split accuracy  \\\n0     iris  Decision Tree Classifier    (5, 2, random)  holdout     0.88   \n2     iris  Decision Tree Classifier      (5, 2, best)  holdout      0.9   \n4     iris  Decision Tree Classifier   (5, 20, random)  holdout     0.48   \n6     iris  Decision Tree Classifier     (5, 20, best)  holdout      0.9   \n8     iris  Decision Tree Classifier   (5, 40, random)  holdout     0.28   \n10    iris  Decision Tree Classifier     (5, 40, best)  holdout     0.54   \n12    iris  Decision Tree Classifier   (10, 2, random)  holdout      0.9   \n14    iris  Decision Tree Classifier     (10, 2, best)  holdout      0.9   \n16    iris  Decision Tree Classifier  (10, 20, random)  holdout     0.48   \n18    iris  Decision Tree Classifier    (10, 20, best)  holdout      0.9   \n20    iris  Decision Tree Classifier  (10, 40, random)  holdout     0.28   \n22    iris  Decision Tree Classifier    (10, 40, best)  holdout     0.54   \n24    iris  Decision Tree Classifier   (15, 2, random)  holdout      0.9   \n26    iris  Decision Tree Classifier     (15, 2, best)  holdout      0.9   \n28    iris  Decision Tree Classifier  (15, 20, random)  holdout     0.48   \n30    iris  Decision Tree Classifier    (15, 20, best)  holdout      0.9   \n32    iris  Decision Tree Classifier  (15, 40, random)  holdout     0.28   \n34    iris  Decision Tree Classifier    (15, 40, best)  holdout     0.54   \n\n    precision    recall time training time testing  \n0    0.890278  0.865079    0.00099659            0  \n2     0.90305  0.912698             0            0  \n4        0.45  0.555556             0            0  \n6     0.90305  0.912698             0            0  \n8   0.0933333  0.333333   0.000997543            0  \n10    0.41533  0.619048   0.000997305            0  \n12   0.894956  0.904762   0.000997543            0  \n14    0.90305  0.912698             0  0.000997305  \n16       0.45  0.555556   0.000997543            0  \n18    0.90305  0.912698   0.000995874            0  \n20  0.0933333  0.333333             0            0  \n22    0.41533  0.619048             0            0  \n24   0.894956  0.904762   0.000999212            0  \n26    0.90305  0.912698             0  0.000968695  \n28       0.45  0.555556   0.000996351            0  \n30    0.90305  0.912698   0.000994921            0  \n32  0.0933333  0.333333             0  0.000997066  \n34    0.41533  0.619048   0.000997066            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.890278</td>\n      <td>0.865079</td>\n      <td>0.00099659</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000997305</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000995874</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000999212</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000968695</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000996351</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000994921</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0.000997066</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n1     iris  Decision Tree Classifier    (5, 2, random)  k-fold   \n3     iris  Decision Tree Classifier      (5, 2, best)  k-fold   \n5     iris  Decision Tree Classifier   (5, 20, random)  k-fold   \n7     iris  Decision Tree Classifier     (5, 20, best)  k-fold   \n9     iris  Decision Tree Classifier   (5, 40, random)  k-fold   \n11    iris  Decision Tree Classifier     (5, 40, best)  k-fold   \n13    iris  Decision Tree Classifier   (10, 2, random)  k-fold   \n15    iris  Decision Tree Classifier     (10, 2, best)  k-fold   \n17    iris  Decision Tree Classifier  (10, 20, random)  k-fold   \n19    iris  Decision Tree Classifier    (10, 20, best)  k-fold   \n21    iris  Decision Tree Classifier  (10, 40, random)  k-fold   \n23    iris  Decision Tree Classifier    (10, 40, best)  k-fold   \n25    iris  Decision Tree Classifier   (15, 2, random)  k-fold   \n27    iris  Decision Tree Classifier     (15, 2, best)  k-fold   \n29    iris  Decision Tree Classifier  (15, 20, random)  k-fold   \n31    iris  Decision Tree Classifier    (15, 20, best)  k-fold   \n33    iris  Decision Tree Classifier  (15, 40, random)  k-fold   \n35    iris  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n1    m: 0.8800000000000001 std: 0.05416025603090639   \n3    m: 0.9400000000000001 std: 0.04422166387140532   \n5   m: 0.5599999999999999 std: 0.024944382578492935   \n7    m: 0.9266666666666667 std: 0.04422166387140532   \n9                    m: 0.3333333333333333 std: 0.0   \n11   m: 0.7666666666666666 std: 0.12292725943057185   \n13   m: 0.9199999999999999 std: 0.04521553322083511   \n15   m: 0.9400000000000001 std: 0.04422166387140532   \n17  m: 0.5599999999999999 std: 0.024944382578492935   \n19   m: 0.9266666666666667 std: 0.04422166387140532   \n21                   m: 0.3333333333333333 std: 0.0   \n23   m: 0.7666666666666666 std: 0.12292725943057185   \n25   m: 0.9199999999999999 std: 0.04521553322083511   \n27   m: 0.9400000000000001 std: 0.04422166387140532   \n29  m: 0.5599999999999999 std: 0.024944382578492935   \n31   m: 0.9266666666666667 std: 0.04422166387140532   \n33                   m: 0.3333333333333333 std: 0.0   \n35   m: 0.7666666666666666 std: 0.12292725943057185   \n\n                                            precision  \\\n1      m: 0.9151709401709403 std: 0.02856862378351845   \n3      m: 0.9444949494949496 std: 0.04164152899506982   \n5    m: 0.47716293368467283 std: 0.004696804926703416   \n7      m: 0.9332491582491583 std: 0.04255264892173636   \n9   m: 0.11111111111111112 std: 1.3877787807814457...   \n11     m: 0.6693602693602694 std: 0.20784967494940076   \n13     m: 0.9307840307840308 std: 0.03813348030226439   \n15     m: 0.9444949494949496 std: 0.04164152899506982   \n17   m: 0.47716293368467283 std: 0.004696804926703416   \n19     m: 0.9332491582491583 std: 0.04255264892173636   \n21  m: 0.11111111111111112 std: 1.3877787807814457...   \n23     m: 0.6693602693602694 std: 0.20784967494940076   \n25     m: 0.9307840307840308 std: 0.03813348030226439   \n27     m: 0.9444949494949496 std: 0.04164152899506982   \n29   m: 0.47716293368467283 std: 0.004696804926703416   \n31     m: 0.9332491582491583 std: 0.04255264892173636   \n33  m: 0.11111111111111112 std: 1.3877787807814457...   \n35     m: 0.6693602693602694 std: 0.20784967494940076   \n\n                                             recall  \\\n1    m: 0.8799999999999999 std: 0.05416025603090637   \n3   m: 0.9400000000000001 std: 0.044221663871405366   \n5   m: 0.5599999999999999 std: 0.024944382578492935   \n7   m: 0.9266666666666665 std: 0.044221663871405345   \n9                    m: 0.3333333333333333 std: 0.0   \n11   m: 0.7666666666666666 std: 0.12292725943057183   \n13    m: 0.9199999999999999 std: 0.0452155332208351   \n15  m: 0.9400000000000001 std: 0.044221663871405366   \n17  m: 0.5599999999999999 std: 0.024944382578492935   \n19  m: 0.9266666666666665 std: 0.044221663871405345   \n21                   m: 0.3333333333333333 std: 0.0   \n23   m: 0.7666666666666666 std: 0.12292725943057183   \n25    m: 0.9199999999999999 std: 0.0452155332208351   \n27  m: 0.9400000000000001 std: 0.044221663871405366   \n29  m: 0.5599999999999999 std: 0.024944382578492935   \n31  m: 0.9266666666666665 std: 0.044221663871405345   \n33                   m: 0.3333333333333333 std: 0.0   \n35   m: 0.7666666666666666 std: 0.12292725943057183   \n\n                                        time training  \\\n1   total: 0.004986286163330078 values: [0.0009970...   \n3   total: 0.005007743835449219 values: [0.0009973...   \n5   total: 0.002966165542602539 values: [0.0010004...   \n7   total: 0.001994609832763672 values: [0.0009973...   \n9   total: 0.0020182132720947266 values: [0.      ...   \n11  total: 0.003008127212524414 values: [0.       ...   \n13  total: 0.000997304916381836 values: [0.       ...   \n15  total: 0.00399017333984375 values: [0.        ...   \n17  total: 0.0029053688049316406 values: [0.000910...   \n19  total: 0.001962423324584961 values: [0.       ...   \n21  total: 0.003957986831665039 values: [0.       ...   \n23  total: 0.0030341148376464844 values: [0.001024...   \n25  total: 0.0019943714141845703 values: [0.      ...   \n27  total: 0.004981040954589844 values: [0.0009982...   \n29  total: 0.0009975433349609375 values: [0.      ...   \n31  total: 0.0009970664978027344 values: [0.      ...   \n33  total: 0.003989458084106445 values: [0.       ...   \n35  total: 0.0029926300048828125 values: [0.      ...   \n\n                                         time testing  \n1   total: 0.004987001419067383 values: [0.0009975...  \n3   total: 0.0049974918365478516 values: [0.000997...  \n5   total: 0.007972002029418945 values: [0.0019595...  \n7   total: 0.0069811344146728516 values: [0.000997...  \n9   total: 0.007998228073120117 values: [0.0020265...  \n11  total: 0.0069658756256103516 values: [0.002012...  \n13  total: 0.005967140197753906 values: [0.0019621...  \n15  total: 0.004956722259521484 values: [0.0009965...  \n17  total: 0.009946107864379883 values: [0.0009987...  \n19  total: 0.00900721549987793 values: [0.00202441...  \n21  total: 0.009007692337036133 values: [0.0020244...  \n23  total: 0.009942293167114258 values: [0.0019755...  \n25  total: 0.008007287979125977 values: [0.0020215...  \n27  total: 0.006959438323974609 values: [0.0009689...  \n29  total: 0.012934446334838867 values: [0.0059530...  \n31  total: 0.008981704711914062 values: [0.0019881...  \n33  total: 0.008990049362182617 values: [0.0019953...  \n35  total: 0.00897669792175293 values: [0.00199628...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8800000000000001 std: 0.05416025603090639</td>\n      <td>m: 0.9151709401709403 std: 0.02856862378351845</td>\n      <td>m: 0.8799999999999999 std: 0.05416025603090637</td>\n      <td>total: 0.004986286163330078 values: [0.0009970...</td>\n      <td>total: 0.004987001419067383 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.005007743835449219 values: [0.0009973...</td>\n      <td>total: 0.0049974918365478516 values: [0.000997...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.002966165542602539 values: [0.0010004...</td>\n      <td>total: 0.007972002029418945 values: [0.0019595...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.001994609832763672 values: [0.0009973...</td>\n      <td>total: 0.0069811344146728516 values: [0.000997...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0020182132720947266 values: [0.      ...</td>\n      <td>total: 0.007998228073120117 values: [0.0020265...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.003008127212524414 values: [0.       ...</td>\n      <td>total: 0.0069658756256103516 values: [0.002012...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.000997304916381836 values: [0.       ...</td>\n      <td>total: 0.005967140197753906 values: [0.0019621...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.00399017333984375 values: [0.        ...</td>\n      <td>total: 0.004956722259521484 values: [0.0009965...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0029053688049316406 values: [0.000910...</td>\n      <td>total: 0.009946107864379883 values: [0.0009987...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.001962423324584961 values: [0.       ...</td>\n      <td>total: 0.00900721549987793 values: [0.00202441...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003957986831665039 values: [0.       ...</td>\n      <td>total: 0.009007692337036133 values: [0.0020244...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0030341148376464844 values: [0.001024...</td>\n      <td>total: 0.009942293167114258 values: [0.0019755...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0019943714141845703 values: [0.      ...</td>\n      <td>total: 0.008007287979125977 values: [0.0020215...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.004981040954589844 values: [0.0009982...</td>\n      <td>total: 0.006959438323974609 values: [0.0009689...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0009975433349609375 values: [0.      ...</td>\n      <td>total: 0.012934446334838867 values: [0.0059530...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.0009970664978027344 values: [0.      ...</td>\n      <td>total: 0.008981704711914062 values: [0.0019881...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003989458084106445 values: [0.       ...</td>\n      <td>total: 0.008990049362182617 values: [0.0019953...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0029926300048828125 values: [0.      ...</td>\n      <td>total: 0.00897669792175293 values: [0.00199628...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetIris = datasets.load_iris();\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 10,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetIris.data, datasetIris.target),max_depth=5)\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='holdout')])\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split  accuracy  \\\n36  digits  Decision Tree Classifier    (5, 2, random)  holdout  0.673401   \n38  digits  Decision Tree Classifier      (5, 2, best)  holdout    0.6633   \n40  digits  Decision Tree Classifier   (5, 20, random)  holdout  0.643098   \n42  digits  Decision Tree Classifier     (5, 20, best)  holdout  0.658249   \n44  digits  Decision Tree Classifier   (5, 40, random)  holdout  0.624579   \n46  digits  Decision Tree Classifier     (5, 40, best)  holdout  0.607744   \n48  digits  Decision Tree Classifier   (10, 2, random)  holdout  0.821549   \n50  digits  Decision Tree Classifier     (10, 2, best)  holdout  0.833333   \n52  digits  Decision Tree Classifier  (10, 20, random)  holdout  0.742424   \n54  digits  Decision Tree Classifier    (10, 20, best)  holdout  0.794613   \n56  digits  Decision Tree Classifier  (10, 40, random)  holdout  0.621212   \n58  digits  Decision Tree Classifier    (10, 40, best)  holdout  0.734007   \n60  digits  Decision Tree Classifier   (15, 2, random)  holdout  0.826599   \n62  digits  Decision Tree Classifier     (15, 2, best)  holdout   0.83165   \n64  digits  Decision Tree Classifier  (15, 20, random)  holdout  0.742424   \n66  digits  Decision Tree Classifier    (15, 20, best)  holdout  0.794613   \n68  digits  Decision Tree Classifier  (15, 40, random)  holdout  0.621212   \n70  digits  Decision Tree Classifier    (15, 40, best)  holdout  0.734007   \n\n   precision    recall time training time testing  \n36  0.717454  0.677103    0.00298977  0.000997066  \n38  0.746121  0.663671      0.010972  0.000997543  \n40  0.637573  0.641345    0.00299096            0  \n42  0.720075  0.657125    0.00797844            0  \n44  0.595066  0.623683    0.00297952            0  \n46   0.59806  0.604756     0.0069809  0.000997782  \n48  0.827151  0.822762    0.00501871            0  \n50   0.84214  0.836688     0.0139635            0  \n52  0.749126  0.743035    0.00299191  0.000997782  \n54   0.80054  0.797709    0.00900817  0.000998735  \n56  0.649174  0.622869    0.00299168            0  \n58  0.764335   0.73374    0.00894618  0.000997543  \n60  0.832276  0.828587    0.00498676            0  \n62  0.839983  0.835681     0.0139632            0  \n64  0.749126  0.743035    0.00299168  0.000997782  \n66   0.80054  0.797709    0.00997281            0  \n68  0.649174  0.622869    0.00300646            0  \n70  0.764335   0.73374    0.00897861            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.673401</td>\n      <td>0.717454</td>\n      <td>0.677103</td>\n      <td>0.00298977</td>\n      <td>0.000997066</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.6633</td>\n      <td>0.746121</td>\n      <td>0.663671</td>\n      <td>0.010972</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.643098</td>\n      <td>0.637573</td>\n      <td>0.641345</td>\n      <td>0.00299096</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.658249</td>\n      <td>0.720075</td>\n      <td>0.657125</td>\n      <td>0.00797844</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.624579</td>\n      <td>0.595066</td>\n      <td>0.623683</td>\n      <td>0.00297952</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.607744</td>\n      <td>0.59806</td>\n      <td>0.604756</td>\n      <td>0.0069809</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.821549</td>\n      <td>0.827151</td>\n      <td>0.822762</td>\n      <td>0.00501871</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.84214</td>\n      <td>0.836688</td>\n      <td>0.0139635</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00299191</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00900817</td>\n      <td>0.000998735</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00894618</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.826599</td>\n      <td>0.832276</td>\n      <td>0.828587</td>\n      <td>0.00498676</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.83165</td>\n      <td>0.839983</td>\n      <td>0.835681</td>\n      <td>0.0139632</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00299168</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00997281</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00300646</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00897861</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n37  digits  Decision Tree Classifier    (5, 2, random)  k-fold   \n39  digits  Decision Tree Classifier      (5, 2, best)  k-fold   \n41  digits  Decision Tree Classifier   (5, 20, random)  k-fold   \n43  digits  Decision Tree Classifier     (5, 20, best)  k-fold   \n45  digits  Decision Tree Classifier   (5, 40, random)  k-fold   \n47  digits  Decision Tree Classifier     (5, 40, best)  k-fold   \n49  digits  Decision Tree Classifier   (10, 2, random)  k-fold   \n51  digits  Decision Tree Classifier     (10, 2, best)  k-fold   \n53  digits  Decision Tree Classifier  (10, 20, random)  k-fold   \n55  digits  Decision Tree Classifier    (10, 20, best)  k-fold   \n57  digits  Decision Tree Classifier  (10, 40, random)  k-fold   \n59  digits  Decision Tree Classifier    (10, 40, best)  k-fold   \n61  digits  Decision Tree Classifier   (15, 2, random)  k-fold   \n63  digits  Decision Tree Classifier     (15, 2, best)  k-fold   \n65  digits  Decision Tree Classifier  (15, 20, random)  k-fold   \n67  digits  Decision Tree Classifier    (15, 20, best)  k-fold   \n69  digits  Decision Tree Classifier  (15, 40, random)  k-fold   \n71  digits  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n37     m: 0.682799442896936 std: 0.0225789955736832   \n39  m: 0.6521990095945527 std: 0.029293764851288196   \n41  m: 0.6750278551532034 std: 0.040755563742608684   \n43   m: 0.642189724543485 std: 0.026859596447899876   \n45   m: 0.6282559579077684 std: 0.04962782791262363   \n47  m: 0.6271649644073042 std: 0.022340010709646117   \n49  m: 0.8492169606932837 std: 0.024701250873822116   \n51  m: 0.8497415660786135 std: 0.016289255420700997   \n53  m: 0.7334292788610337 std: 0.020905478914734647   \n55   m: 0.7879712163416899 std: 0.01638106112774851   \n57  m: 0.6956360259981429 std: 0.030311998503533933   \n59   m: 0.7551593933766635 std: 0.02118747834909684   \n61    m: 0.8480857319715259 std: 0.0160451900425344   \n63  m: 0.8503002166511916 std: 0.009784061096593345   \n65  m: 0.7334292788610337 std: 0.020905478914734647   \n67   m: 0.7879712163416899 std: 0.01638106112774851   \n69  m: 0.6956360259981429 std: 0.030311998503533933   \n71   m: 0.7551593933766635 std: 0.02118747834909684   \n\n                                          precision  \\\n37   m: 0.717660567564935 std: 0.026132446284686445   \n39   m: 0.7298174310895975 std: 0.01717008365700091   \n41  m: 0.6950497115958991 std: 0.061857032803490745   \n43    m: 0.703735266738326 std: 0.01501969790860612   \n45   m: 0.6253692157304211 std: 0.05839129334704999   \n47   m: 0.6660513441822741 std: 0.02980445680574132   \n49  m: 0.8535964619626707 std: 0.024247845316340284   \n51  m: 0.8559045305923447 std: 0.016949978229067093   \n53   m: 0.7394966477817702 std: 0.02134785363906439   \n55  m: 0.7966323249656977 std: 0.019183878519583475   \n57   m: 0.7156065230428587 std: 0.03517987997097763   \n59  m: 0.7708872928512271 std: 0.018327983630086836   \n61  m: 0.8518270691602231 std: 0.014618370518263432   \n63  m: 0.8570756527976207 std: 0.010812556072823007   \n65   m: 0.7394966477817702 std: 0.02134785363906439   \n67  m: 0.7966323249656977 std: 0.019183878519583475   \n69   m: 0.7156065230428587 std: 0.03517987997097763   \n71  m: 0.7708872928512271 std: 0.018327983630086836   \n\n                                             recall  \\\n37  m: 0.6822451106568753 std: 0.022306835943359964   \n39  m: 0.6520541549953315 std: 0.028721061472361847   \n41    m: 0.674860019683549 std: 0.04133979548873456   \n43  m: 0.6420215509627274 std: 0.026807715646732715   \n45  m: 0.6283112019582608 std: 0.050742761166004666   \n47  m: 0.6270297019708784 std: 0.022343553593636677   \n49   m: 0.848803896333308 std: 0.024983989383474584   \n51  m: 0.8496446109975521 std: 0.016132101050840803   \n53   m: 0.7331400055517703 std: 0.02089872408546371   \n55    m: 0.7882291114644057 std: 0.0162673398542481   \n57   m: 0.6946652282534636 std: 0.03080685318605075   \n59   m: 0.754918641330406 std: 0.021705452983571242   \n61   m: 0.847657531481061 std: 0.016500416901784897   \n63  m: 0.8501242334771746 std: 0.009676746964727485   \n65   m: 0.7331400055517703 std: 0.02089872408546371   \n67    m: 0.7882291114644057 std: 0.0162673398542481   \n69   m: 0.6946652282534636 std: 0.03080685318605075   \n71   m: 0.754918641330406 std: 0.021705452983571242   \n\n                                        time training  \\\n37  total: 0.028920888900756836 values: [0.0049846...   \n39  total: 0.06482982635498047 values: [0.01196933...   \n41  total: 0.021940946578979492 values: [0.0049874...   \n43  total: 0.04886913299560547 values: [0.00997281...   \n45  total: 0.01900506019592285 values: [0.00398517...   \n47  total: 0.04684734344482422 values: [0.00897574...   \n49  total: 0.03191232681274414 values: [0.00694966...   \n51  total: 0.07774758338928223 values: [0.01592493...   \n53  total: 0.022938013076782227 values: [0.0039889...   \n55  total: 0.06482529640197754 values: [0.01296425...   \n57  total: 0.020895957946777344 values: [0.0049526...   \n59  total: 0.05485177040100098 values: [0.01097035...   \n61  total: 0.03197884559631348 values: [0.00698113...   \n63  total: 0.08279752731323242 values: [0.0169549 ...   \n65  total: 0.022937297821044922 values: [0.0039892...   \n67  total: 0.06186532974243164 values: [0.01196742...   \n69  total: 0.019953012466430664 values: [0.0039923...   \n71  total: 0.054949045181274414 values: [0.0109748...   \n\n                                         time testing  \n37  total: 0.009973526000976562 values: [0.0019960...  \n39  total: 0.00997304916381836 values: [0.00199485...  \n41  total: 0.009973526000976562 values: [0.0029909...  \n43  total: 0.00997304916381836 values: [0.00199485...  \n45  total: 0.008919239044189453 values: [0.0019950...  \n47  total: 0.009006738662719727 values: [0.0019977...  \n49  total: 0.007977724075317383 values: [0.0009980...  \n51  total: 0.008978128433227539 values: [0.0019953...  \n53  total: 0.008977651596069336 values: [0.0019950...  \n55  total: 0.00897359848022461 values: [0.00099754...  \n57  total: 0.0080108642578125 values: [0.00099778 ...  \n59  total: 0.008977174758911133 values: [0.0009977...  \n61  total: 0.006985902786254883 values: [0.0009975...  \n63  total: 0.006951332092285156 values: [0.0009977...  \n65  total: 0.006983041763305664 values: [0.0019948...  \n67  total: 0.0079803466796875 values: [0.00099802 ...  \n69  total: 0.009967565536499023 values: [0.0019919...  \n71  total: 0.005019426345825195 values: [0.0009949...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.682799442896936 std: 0.0225789955736832</td>\n      <td>m: 0.717660567564935 std: 0.026132446284686445</td>\n      <td>m: 0.6822451106568753 std: 0.022306835943359964</td>\n      <td>total: 0.028920888900756836 values: [0.0049846...</td>\n      <td>total: 0.009973526000976562 values: [0.0019960...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6521990095945527 std: 0.029293764851288196</td>\n      <td>m: 0.7298174310895975 std: 0.01717008365700091</td>\n      <td>m: 0.6520541549953315 std: 0.028721061472361847</td>\n      <td>total: 0.06482982635498047 values: [0.01196933...</td>\n      <td>total: 0.00997304916381836 values: [0.00199485...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6750278551532034 std: 0.040755563742608684</td>\n      <td>m: 0.6950497115958991 std: 0.061857032803490745</td>\n      <td>m: 0.674860019683549 std: 0.04133979548873456</td>\n      <td>total: 0.021940946578979492 values: [0.0049874...</td>\n      <td>total: 0.009973526000976562 values: [0.0029909...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.642189724543485 std: 0.026859596447899876</td>\n      <td>m: 0.703735266738326 std: 0.01501969790860612</td>\n      <td>m: 0.6420215509627274 std: 0.026807715646732715</td>\n      <td>total: 0.04886913299560547 values: [0.00997281...</td>\n      <td>total: 0.00997304916381836 values: [0.00199485...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6282559579077684 std: 0.04962782791262363</td>\n      <td>m: 0.6253692157304211 std: 0.05839129334704999</td>\n      <td>m: 0.6283112019582608 std: 0.050742761166004666</td>\n      <td>total: 0.01900506019592285 values: [0.00398517...</td>\n      <td>total: 0.008919239044189453 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6271649644073042 std: 0.022340010709646117</td>\n      <td>m: 0.6660513441822741 std: 0.02980445680574132</td>\n      <td>m: 0.6270297019708784 std: 0.022343553593636677</td>\n      <td>total: 0.04684734344482422 values: [0.00897574...</td>\n      <td>total: 0.009006738662719727 values: [0.0019977...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8492169606932837 std: 0.024701250873822116</td>\n      <td>m: 0.8535964619626707 std: 0.024247845316340284</td>\n      <td>m: 0.848803896333308 std: 0.024983989383474584</td>\n      <td>total: 0.03191232681274414 values: [0.00694966...</td>\n      <td>total: 0.007977724075317383 values: [0.0009980...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8497415660786135 std: 0.016289255420700997</td>\n      <td>m: 0.8559045305923447 std: 0.016949978229067093</td>\n      <td>m: 0.8496446109975521 std: 0.016132101050840803</td>\n      <td>total: 0.07774758338928223 values: [0.01592493...</td>\n      <td>total: 0.008978128433227539 values: [0.0019953...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.022938013076782227 values: [0.0039889...</td>\n      <td>total: 0.008977651596069336 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.06482529640197754 values: [0.01296425...</td>\n      <td>total: 0.00897359848022461 values: [0.00099754...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.020895957946777344 values: [0.0049526...</td>\n      <td>total: 0.0080108642578125 values: [0.00099778 ...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.05485177040100098 values: [0.01097035...</td>\n      <td>total: 0.008977174758911133 values: [0.0009977...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8480857319715259 std: 0.0160451900425344</td>\n      <td>m: 0.8518270691602231 std: 0.014618370518263432</td>\n      <td>m: 0.847657531481061 std: 0.016500416901784897</td>\n      <td>total: 0.03197884559631348 values: [0.00698113...</td>\n      <td>total: 0.006985902786254883 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8503002166511916 std: 0.009784061096593345</td>\n      <td>m: 0.8570756527976207 std: 0.010812556072823007</td>\n      <td>m: 0.8501242334771746 std: 0.009676746964727485</td>\n      <td>total: 0.08279752731323242 values: [0.0169549 ...</td>\n      <td>total: 0.006951332092285156 values: [0.0009977...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.022937297821044922 values: [0.0039892...</td>\n      <td>total: 0.006983041763305664 values: [0.0019948...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.06186532974243164 values: [0.01196742...</td>\n      <td>total: 0.0079803466796875 values: [0.00099802 ...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.019953012466430664 values: [0.0039923...</td>\n      <td>total: 0.009967565536499023 values: [0.0019919...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.054949045181274414 values: [0.0109748...</td>\n      <td>total: 0.005019426345825195 values: [0.0009949...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetDigits = datasets.load_digits();\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 10,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetDigits.data, datasetDigits.target),max_depth=5)\n",
    "\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='holdout')])\n",
    "display(decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Results:\n",
    "* Random and Best Splitting Approach for the Decision Tree on both the Iris and Digits Dataset:\n",
    "The overall results indicate that the \"best\" splitting parameter yields by far superior results compared to the \"random\" approach.\n",
    "* Min Sample Leaf Values: Additional analyses of the results from the previous step show that there is overfitting after a max depth of 2 with only limited benefits of additional splits.\n",
    "To counteract the creation of additional nodes, min_samples_leaf was added as parameter for an extensive high maximum depth (30).\n",
    "* Analysis using the Decision Tree approach on the Digits Dataset show a high relevance of the defined max tree depth for accuracy, precision and recall with extremely low training and testing time. For a max depth of 7, the resulting tree yields good results with limited overfitting. Potential subsequent pruning could further reduce overfitting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overall Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "overall_results = knn_results + bayes_results + perceptron_results + decision_tree_results\n",
    "overall_results_df = pd.DataFrame(overall_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iris Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split accuracy  \\\n0     iris                       kNN               n=3  holdout     0.94   \n2     iris                       kNN              n=10  holdout     0.92   \n4     iris                       kNN              n=15  holdout     0.92   \n12    iris                     bayes              none  holdout      0.9   \n16    iris                perceptron              none  holdout     0.34   \n20    iris  Decision Tree Classifier    (5, 2, random)  holdout     0.88   \n22    iris  Decision Tree Classifier      (5, 2, best)  holdout      0.9   \n24    iris  Decision Tree Classifier   (5, 20, random)  holdout     0.48   \n26    iris  Decision Tree Classifier     (5, 20, best)  holdout      0.9   \n28    iris  Decision Tree Classifier   (5, 40, random)  holdout     0.28   \n30    iris  Decision Tree Classifier     (5, 40, best)  holdout     0.54   \n32    iris  Decision Tree Classifier   (10, 2, random)  holdout      0.9   \n34    iris  Decision Tree Classifier     (10, 2, best)  holdout      0.9   \n36    iris  Decision Tree Classifier  (10, 20, random)  holdout     0.48   \n38    iris  Decision Tree Classifier    (10, 20, best)  holdout      0.9   \n40    iris  Decision Tree Classifier  (10, 40, random)  holdout     0.28   \n42    iris  Decision Tree Classifier    (10, 40, best)  holdout     0.54   \n44    iris  Decision Tree Classifier   (15, 2, random)  holdout      0.9   \n46    iris  Decision Tree Classifier     (15, 2, best)  holdout      0.9   \n48    iris  Decision Tree Classifier  (15, 20, random)  holdout     0.48   \n50    iris  Decision Tree Classifier    (15, 20, best)  holdout      0.9   \n52    iris  Decision Tree Classifier  (15, 40, random)  holdout     0.28   \n54    iris  Decision Tree Classifier    (15, 40, best)  holdout     0.54   \n\n    precision    recall time training time testing  \n0    0.941176  0.952381             0    0.0029912  \n2    0.925926  0.936508    0.00100708   0.00198483  \n4    0.925926  0.936508   0.000997543   0.00199461  \n12    0.90305  0.912698   0.000997305            0  \n16   0.432624       0.4    0.00202298            0  \n20   0.890278  0.865079    0.00099659            0  \n22    0.90305  0.912698             0            0  \n24       0.45  0.555556             0            0  \n26    0.90305  0.912698             0            0  \n28  0.0933333  0.333333   0.000997543            0  \n30    0.41533  0.619048   0.000997305            0  \n32   0.894956  0.904762   0.000997543            0  \n34    0.90305  0.912698             0  0.000997305  \n36       0.45  0.555556   0.000997543            0  \n38    0.90305  0.912698   0.000995874            0  \n40  0.0933333  0.333333             0            0  \n42    0.41533  0.619048             0            0  \n44   0.894956  0.904762   0.000999212            0  \n46    0.90305  0.912698             0  0.000968695  \n48       0.45  0.555556   0.000996351            0  \n50    0.90305  0.912698   0.000994921            0  \n52  0.0933333  0.333333             0  0.000997066  \n54    0.41533  0.619048   0.000997066            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>holdout</td>\n      <td>0.94</td>\n      <td>0.941176</td>\n      <td>0.952381</td>\n      <td>0</td>\n      <td>0.0029912</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0.00100708</td>\n      <td>0.00198483</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0.000997543</td>\n      <td>0.00199461</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.34</td>\n      <td>0.432624</td>\n      <td>0.4</td>\n      <td>0.00202298</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.890278</td>\n      <td>0.865079</td>\n      <td>0.00099659</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000997305</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000997543</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000995874</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.894956</td>\n      <td>0.904762</td>\n      <td>0.000999212</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0</td>\n      <td>0.000968695</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.48</td>\n      <td>0.45</td>\n      <td>0.555556</td>\n      <td>0.000996351</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.000994921</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.28</td>\n      <td>0.0933333</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0.000997066</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.54</td>\n      <td>0.41533</td>\n      <td>0.619048</td>\n      <td>0.000997066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n1     iris                       kNN               n=3  k-fold   \n3     iris                       kNN              n=10  k-fold   \n5     iris                       kNN              n=15  k-fold   \n13    iris                     bayes              none  k-fold   \n17    iris                perceptron              none  k-fold   \n21    iris  Decision Tree Classifier    (5, 2, random)  k-fold   \n23    iris  Decision Tree Classifier      (5, 2, best)  k-fold   \n25    iris  Decision Tree Classifier   (5, 20, random)  k-fold   \n27    iris  Decision Tree Classifier     (5, 20, best)  k-fold   \n29    iris  Decision Tree Classifier   (5, 40, random)  k-fold   \n31    iris  Decision Tree Classifier     (5, 40, best)  k-fold   \n33    iris  Decision Tree Classifier   (10, 2, random)  k-fold   \n35    iris  Decision Tree Classifier     (10, 2, best)  k-fold   \n37    iris  Decision Tree Classifier  (10, 20, random)  k-fold   \n39    iris  Decision Tree Classifier    (10, 20, best)  k-fold   \n41    iris  Decision Tree Classifier  (10, 40, random)  k-fold   \n43    iris  Decision Tree Classifier    (10, 40, best)  k-fold   \n45    iris  Decision Tree Classifier   (15, 2, random)  k-fold   \n47    iris  Decision Tree Classifier     (15, 2, best)  k-fold   \n49    iris  Decision Tree Classifier  (15, 20, random)  k-fold   \n51    iris  Decision Tree Classifier    (15, 20, best)  k-fold   \n53    iris  Decision Tree Classifier  (15, 40, random)  k-fold   \n55    iris  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n1   m: 0.9600000000000002 std: 0.024944382578492935   \n3    m: 0.9733333333333334 std: 0.05333333333333332   \n5   m: 0.9733333333333334 std: 0.038873012632301994   \n13   m: 0.9533333333333334 std: 0.03399346342395189   \n17                 m: 0.74 std: 0.10413666234542207   \n21   m: 0.8800000000000001 std: 0.05416025603090639   \n23   m: 0.9400000000000001 std: 0.04422166387140532   \n25  m: 0.5599999999999999 std: 0.024944382578492935   \n27   m: 0.9266666666666667 std: 0.04422166387140532   \n29                   m: 0.3333333333333333 std: 0.0   \n31   m: 0.7666666666666666 std: 0.12292725943057185   \n33   m: 0.9199999999999999 std: 0.04521553322083511   \n35   m: 0.9400000000000001 std: 0.04422166387140532   \n37  m: 0.5599999999999999 std: 0.024944382578492935   \n39   m: 0.9266666666666667 std: 0.04422166387140532   \n41                   m: 0.3333333333333333 std: 0.0   \n43   m: 0.7666666666666666 std: 0.12292725943057185   \n45   m: 0.9199999999999999 std: 0.04521553322083511   \n47   m: 0.9400000000000001 std: 0.04422166387140532   \n49  m: 0.5599999999999999 std: 0.024944382578492935   \n51   m: 0.9266666666666667 std: 0.04422166387140532   \n53                   m: 0.3333333333333333 std: 0.0   \n55   m: 0.7666666666666666 std: 0.12292725943057185   \n\n                                            precision  \\\n1      m: 0.9612121212121212 std: 0.02530983396099532   \n3                  m: 0.975 std: 0.049999999999999996   \n5     m: 0.9744107744107744 std: 0.037890383559960134   \n13     m: 0.9550168350168351 std: 0.03375719358407477   \n17     m: 0.6742889463477699 std: 0.19998100699035673   \n21     m: 0.9151709401709403 std: 0.02856862378351845   \n23     m: 0.9444949494949496 std: 0.04164152899506982   \n25   m: 0.47716293368467283 std: 0.004696804926703416   \n27     m: 0.9332491582491583 std: 0.04255264892173636   \n29  m: 0.11111111111111112 std: 1.3877787807814457...   \n31     m: 0.6693602693602694 std: 0.20784967494940076   \n33     m: 0.9307840307840308 std: 0.03813348030226439   \n35     m: 0.9444949494949496 std: 0.04164152899506982   \n37   m: 0.47716293368467283 std: 0.004696804926703416   \n39     m: 0.9332491582491583 std: 0.04255264892173636   \n41  m: 0.11111111111111112 std: 1.3877787807814457...   \n43     m: 0.6693602693602694 std: 0.20784967494940076   \n45     m: 0.9307840307840308 std: 0.03813348030226439   \n47     m: 0.9444949494949496 std: 0.04164152899506982   \n49   m: 0.47716293368467283 std: 0.004696804926703416   \n51     m: 0.9332491582491583 std: 0.04255264892173636   \n53  m: 0.11111111111111112 std: 1.3877787807814457...   \n55     m: 0.6693602693602694 std: 0.20784967494940076   \n\n                                             recall  \\\n1                 m: 0.96 std: 0.024944382578492984   \n3   m: 0.9733333333333334 std: 0.053333333333333365   \n5   m: 0.9733333333333334 std: 0.038873012632301994   \n13    m: 0.9533333333333334 std: 0.0339934634239519   \n17                 m: 0.74 std: 0.10413666234542203   \n21   m: 0.8799999999999999 std: 0.05416025603090637   \n23  m: 0.9400000000000001 std: 0.044221663871405366   \n25  m: 0.5599999999999999 std: 0.024944382578492935   \n27  m: 0.9266666666666665 std: 0.044221663871405345   \n29                   m: 0.3333333333333333 std: 0.0   \n31   m: 0.7666666666666666 std: 0.12292725943057183   \n33    m: 0.9199999999999999 std: 0.0452155332208351   \n35  m: 0.9400000000000001 std: 0.044221663871405366   \n37  m: 0.5599999999999999 std: 0.024944382578492935   \n39  m: 0.9266666666666665 std: 0.044221663871405345   \n41                   m: 0.3333333333333333 std: 0.0   \n43   m: 0.7666666666666666 std: 0.12292725943057183   \n45    m: 0.9199999999999999 std: 0.0452155332208351   \n47  m: 0.9400000000000001 std: 0.044221663871405366   \n49  m: 0.5599999999999999 std: 0.024944382578492935   \n51  m: 0.9266666666666665 std: 0.044221663871405345   \n53                   m: 0.3333333333333333 std: 0.0   \n55   m: 0.7666666666666666 std: 0.12292725943057183   \n\n                                        time training  \\\n1   total: 0.0029926300048828125 values: [0.000997...   \n3   total: 0.0019941329956054688 values: [0.      ...   \n5   total: 0.0019826889038085938 values: [0.000985...   \n13  total: 0.0029859542846679688 values: [0.000996...   \n17  total: 0.009000301361083984 values: [0.0019946...   \n21  total: 0.004986286163330078 values: [0.0009970...   \n23  total: 0.005007743835449219 values: [0.0009973...   \n25  total: 0.002966165542602539 values: [0.0010004...   \n27  total: 0.001994609832763672 values: [0.0009973...   \n29  total: 0.0020182132720947266 values: [0.      ...   \n31  total: 0.003008127212524414 values: [0.       ...   \n33  total: 0.000997304916381836 values: [0.       ...   \n35  total: 0.00399017333984375 values: [0.        ...   \n37  total: 0.0029053688049316406 values: [0.000910...   \n39  total: 0.001962423324584961 values: [0.       ...   \n41  total: 0.003957986831665039 values: [0.       ...   \n43  total: 0.0030341148376464844 values: [0.001024...   \n45  total: 0.0019943714141845703 values: [0.      ...   \n47  total: 0.004981040954589844 values: [0.0009982...   \n49  total: 0.0009975433349609375 values: [0.      ...   \n51  total: 0.0009970664978027344 values: [0.      ...   \n53  total: 0.003989458084106445 values: [0.       ...   \n55  total: 0.0029926300048828125 values: [0.      ...   \n\n                                         time testing  \n1   total: 0.013962507247924805 values: [0.0029921...  \n3   total: 0.012965917587280273 values: [0.0029921...  \n5   total: 0.014960050582885742 values: [0.0029919...  \n13  total: 0.005992412567138672 values: [0.0009999...  \n17  total: 0.008951425552368164 values: [0.0029592...  \n21  total: 0.004987001419067383 values: [0.0009975...  \n23  total: 0.0049974918365478516 values: [0.000997...  \n25  total: 0.007972002029418945 values: [0.0019595...  \n27  total: 0.0069811344146728516 values: [0.000997...  \n29  total: 0.007998228073120117 values: [0.0020265...  \n31  total: 0.0069658756256103516 values: [0.002012...  \n33  total: 0.005967140197753906 values: [0.0019621...  \n35  total: 0.004956722259521484 values: [0.0009965...  \n37  total: 0.009946107864379883 values: [0.0009987...  \n39  total: 0.00900721549987793 values: [0.00202441...  \n41  total: 0.009007692337036133 values: [0.0020244...  \n43  total: 0.009942293167114258 values: [0.0019755...  \n45  total: 0.008007287979125977 values: [0.0020215...  \n47  total: 0.006959438323974609 values: [0.0009689...  \n49  total: 0.012934446334838867 values: [0.0059530...  \n51  total: 0.008981704711914062 values: [0.0019881...  \n53  total: 0.008990049362182617 values: [0.0019953...  \n55  total: 0.00897669792175293 values: [0.00199628...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>k-fold</td>\n      <td>m: 0.9600000000000002 std: 0.024944382578492935</td>\n      <td>m: 0.9612121212121212 std: 0.02530983396099532</td>\n      <td>m: 0.96 std: 0.024944382578492984</td>\n      <td>total: 0.0029926300048828125 values: [0.000997...</td>\n      <td>total: 0.013962507247924805 values: [0.0029921...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.05333333333333332</td>\n      <td>m: 0.975 std: 0.049999999999999996</td>\n      <td>m: 0.9733333333333334 std: 0.053333333333333365</td>\n      <td>total: 0.0019941329956054688 values: [0.      ...</td>\n      <td>total: 0.012965917587280273 values: [0.0029921...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.038873012632301994</td>\n      <td>m: 0.9744107744107744 std: 0.037890383559960134</td>\n      <td>m: 0.9733333333333334 std: 0.038873012632301994</td>\n      <td>total: 0.0019826889038085938 values: [0.000985...</td>\n      <td>total: 0.014960050582885742 values: [0.0029919...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9533333333333334 std: 0.03399346342395189</td>\n      <td>m: 0.9550168350168351 std: 0.03375719358407477</td>\n      <td>m: 0.9533333333333334 std: 0.0339934634239519</td>\n      <td>total: 0.0029859542846679688 values: [0.000996...</td>\n      <td>total: 0.005992412567138672 values: [0.0009999...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.74 std: 0.10413666234542207</td>\n      <td>m: 0.6742889463477699 std: 0.19998100699035673</td>\n      <td>m: 0.74 std: 0.10413666234542203</td>\n      <td>total: 0.009000301361083984 values: [0.0019946...</td>\n      <td>total: 0.008951425552368164 values: [0.0029592...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8800000000000001 std: 0.05416025603090639</td>\n      <td>m: 0.9151709401709403 std: 0.02856862378351845</td>\n      <td>m: 0.8799999999999999 std: 0.05416025603090637</td>\n      <td>total: 0.004986286163330078 values: [0.0009970...</td>\n      <td>total: 0.004987001419067383 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.005007743835449219 values: [0.0009973...</td>\n      <td>total: 0.0049974918365478516 values: [0.000997...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.002966165542602539 values: [0.0010004...</td>\n      <td>total: 0.007972002029418945 values: [0.0019595...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.001994609832763672 values: [0.0009973...</td>\n      <td>total: 0.0069811344146728516 values: [0.000997...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.0020182132720947266 values: [0.      ...</td>\n      <td>total: 0.007998228073120117 values: [0.0020265...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.003008127212524414 values: [0.       ...</td>\n      <td>total: 0.0069658756256103516 values: [0.002012...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.000997304916381836 values: [0.       ...</td>\n      <td>total: 0.005967140197753906 values: [0.0019621...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.00399017333984375 values: [0.        ...</td>\n      <td>total: 0.004956722259521484 values: [0.0009965...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0029053688049316406 values: [0.000910...</td>\n      <td>total: 0.009946107864379883 values: [0.0009987...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.001962423324584961 values: [0.       ...</td>\n      <td>total: 0.00900721549987793 values: [0.00202441...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003957986831665039 values: [0.       ...</td>\n      <td>total: 0.009007692337036133 values: [0.0020244...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0030341148376464844 values: [0.001024...</td>\n      <td>total: 0.009942293167114258 values: [0.0019755...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.9199999999999999 std: 0.04521553322083511</td>\n      <td>m: 0.9307840307840308 std: 0.03813348030226439</td>\n      <td>m: 0.9199999999999999 std: 0.0452155332208351</td>\n      <td>total: 0.0019943714141845703 values: [0.      ...</td>\n      <td>total: 0.008007287979125977 values: [0.0020215...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9400000000000001 std: 0.04422166387140532</td>\n      <td>m: 0.9444949494949496 std: 0.04164152899506982</td>\n      <td>m: 0.9400000000000001 std: 0.044221663871405366</td>\n      <td>total: 0.004981040954589844 values: [0.0009982...</td>\n      <td>total: 0.006959438323974609 values: [0.0009689...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>m: 0.47716293368467283 std: 0.004696804926703416</td>\n      <td>m: 0.5599999999999999 std: 0.024944382578492935</td>\n      <td>total: 0.0009975433349609375 values: [0.      ...</td>\n      <td>total: 0.012934446334838867 values: [0.0059530...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.9266666666666667 std: 0.04422166387140532</td>\n      <td>m: 0.9332491582491583 std: 0.04255264892173636</td>\n      <td>m: 0.9266666666666665 std: 0.044221663871405345</td>\n      <td>total: 0.0009970664978027344 values: [0.      ...</td>\n      <td>total: 0.008981704711914062 values: [0.0019881...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>m: 0.11111111111111112 std: 1.3877787807814457...</td>\n      <td>m: 0.3333333333333333 std: 0.0</td>\n      <td>total: 0.003989458084106445 values: [0.       ...</td>\n      <td>total: 0.008990049362182617 values: [0.0019953...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>iris</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057185</td>\n      <td>m: 0.6693602693602694 std: 0.20784967494940076</td>\n      <td>m: 0.7666666666666666 std: 0.12292725943057183</td>\n      <td>total: 0.0029926300048828125 values: [0.      ...</td>\n      <td>total: 0.00897669792175293 values: [0.00199628...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='k-fold')])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Despite the heterogenous approaches used, acccuracy, precision and recall were good across most approaches with the notable exception of the Perceptron.\n",
    "\n",
    "The data set may hence be prone to ceiling effects for measuring effectiveness for such numerical categorization tasks.\n",
    "\n",
    "### Efficiency\n",
    "In the datasets used as well as in the approaches applied, the training and testing time measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handwritten Numbers Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments    split  accuracy  \\\n6   digits                       kNN               n=3  holdout  0.991582   \n8   digits                       kNN              n=10  holdout  0.976431   \n10  digits                       kNN              n=15  holdout  0.969697   \n14  digits                     bayes              none  holdout  0.833333   \n18  digits                perceptron              none  holdout  0.939394   \n56  digits  Decision Tree Classifier    (5, 2, random)  holdout  0.673401   \n58  digits  Decision Tree Classifier      (5, 2, best)  holdout    0.6633   \n60  digits  Decision Tree Classifier   (5, 20, random)  holdout  0.643098   \n62  digits  Decision Tree Classifier     (5, 20, best)  holdout  0.658249   \n64  digits  Decision Tree Classifier   (5, 40, random)  holdout  0.624579   \n66  digits  Decision Tree Classifier     (5, 40, best)  holdout  0.607744   \n68  digits  Decision Tree Classifier   (10, 2, random)  holdout  0.821549   \n70  digits  Decision Tree Classifier     (10, 2, best)  holdout  0.833333   \n72  digits  Decision Tree Classifier  (10, 20, random)  holdout  0.742424   \n74  digits  Decision Tree Classifier    (10, 20, best)  holdout  0.794613   \n76  digits  Decision Tree Classifier  (10, 40, random)  holdout  0.621212   \n78  digits  Decision Tree Classifier    (10, 40, best)  holdout  0.734007   \n80  digits  Decision Tree Classifier   (15, 2, random)  holdout  0.826599   \n82  digits  Decision Tree Classifier     (15, 2, best)  holdout   0.83165   \n84  digits  Decision Tree Classifier  (15, 20, random)  holdout  0.742424   \n86  digits  Decision Tree Classifier    (15, 20, best)  holdout  0.794613   \n88  digits  Decision Tree Classifier  (15, 40, random)  holdout  0.621212   \n90  digits  Decision Tree Classifier    (15, 40, best)  holdout  0.734007   \n\n   precision    recall time training time testing  \n6    0.99161  0.991301     0.0179558    0.0987611  \n8   0.976702  0.976281      0.017952     0.102726  \n10  0.969727  0.969164     0.0159569     0.092752  \n14  0.850641  0.833908    0.00199437    0.0019691  \n18   0.94141   0.93962     0.0239067            0  \n56  0.717454  0.677103    0.00298977  0.000997066  \n58  0.746121  0.663671      0.010972  0.000997543  \n60  0.637573  0.641345    0.00299096            0  \n62  0.720075  0.657125    0.00797844            0  \n64  0.595066  0.623683    0.00297952            0  \n66   0.59806  0.604756     0.0069809  0.000997782  \n68  0.827151  0.822762    0.00501871            0  \n70   0.84214  0.836688     0.0139635            0  \n72  0.749126  0.743035    0.00299191  0.000997782  \n74   0.80054  0.797709    0.00900817  0.000998735  \n76  0.649174  0.622869    0.00299168            0  \n78  0.764335   0.73374    0.00894618  0.000997543  \n80  0.832276  0.828587    0.00498676            0  \n82  0.839983  0.835681     0.0139632            0  \n84  0.749126  0.743035    0.00299168  0.000997782  \n86   0.80054  0.797709    0.00997281            0  \n88  0.649174  0.622869    0.00300646            0  \n90  0.764335   0.73374    0.00897861            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>holdout</td>\n      <td>0.991582</td>\n      <td>0.99161</td>\n      <td>0.991301</td>\n      <td>0.0179558</td>\n      <td>0.0987611</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.976431</td>\n      <td>0.976702</td>\n      <td>0.976281</td>\n      <td>0.017952</td>\n      <td>0.102726</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>holdout</td>\n      <td>0.969697</td>\n      <td>0.969727</td>\n      <td>0.969164</td>\n      <td>0.0159569</td>\n      <td>0.092752</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.850641</td>\n      <td>0.833908</td>\n      <td>0.00199437</td>\n      <td>0.0019691</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.939394</td>\n      <td>0.94141</td>\n      <td>0.93962</td>\n      <td>0.0239067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>holdout</td>\n      <td>0.673401</td>\n      <td>0.717454</td>\n      <td>0.677103</td>\n      <td>0.00298977</td>\n      <td>0.000997066</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>holdout</td>\n      <td>0.6633</td>\n      <td>0.746121</td>\n      <td>0.663671</td>\n      <td>0.010972</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>holdout</td>\n      <td>0.643098</td>\n      <td>0.637573</td>\n      <td>0.641345</td>\n      <td>0.00299096</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>holdout</td>\n      <td>0.658249</td>\n      <td>0.720075</td>\n      <td>0.657125</td>\n      <td>0.00797844</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>holdout</td>\n      <td>0.624579</td>\n      <td>0.595066</td>\n      <td>0.623683</td>\n      <td>0.00297952</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>holdout</td>\n      <td>0.607744</td>\n      <td>0.59806</td>\n      <td>0.604756</td>\n      <td>0.0069809</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>holdout</td>\n      <td>0.821549</td>\n      <td>0.827151</td>\n      <td>0.822762</td>\n      <td>0.00501871</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.84214</td>\n      <td>0.836688</td>\n      <td>0.0139635</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00299191</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00900817</td>\n      <td>0.000998735</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00299168</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00894618</td>\n      <td>0.000997543</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>holdout</td>\n      <td>0.826599</td>\n      <td>0.832276</td>\n      <td>0.828587</td>\n      <td>0.00498676</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>holdout</td>\n      <td>0.83165</td>\n      <td>0.839983</td>\n      <td>0.835681</td>\n      <td>0.0139632</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>holdout</td>\n      <td>0.742424</td>\n      <td>0.749126</td>\n      <td>0.743035</td>\n      <td>0.00299168</td>\n      <td>0.000997782</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>holdout</td>\n      <td>0.794613</td>\n      <td>0.80054</td>\n      <td>0.797709</td>\n      <td>0.00997281</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>holdout</td>\n      <td>0.621212</td>\n      <td>0.649174</td>\n      <td>0.622869</td>\n      <td>0.00300646</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>holdout</td>\n      <td>0.734007</td>\n      <td>0.764335</td>\n      <td>0.73374</td>\n      <td>0.00897861</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   dataset                  approach         arguments   split  \\\n7   digits                       kNN               n=3  k-fold   \n9   digits                       kNN              n=10  k-fold   \n11  digits                       kNN              n=15  k-fold   \n15  digits                     bayes              none  k-fold   \n19  digits                perceptron              none  k-fold   \n57  digits  Decision Tree Classifier    (5, 2, random)  k-fold   \n59  digits  Decision Tree Classifier      (5, 2, best)  k-fold   \n61  digits  Decision Tree Classifier   (5, 20, random)  k-fold   \n63  digits  Decision Tree Classifier     (5, 20, best)  k-fold   \n65  digits  Decision Tree Classifier   (5, 40, random)  k-fold   \n67  digits  Decision Tree Classifier     (5, 40, best)  k-fold   \n69  digits  Decision Tree Classifier   (10, 2, random)  k-fold   \n71  digits  Decision Tree Classifier     (10, 2, best)  k-fold   \n73  digits  Decision Tree Classifier  (10, 20, random)  k-fold   \n75  digits  Decision Tree Classifier    (10, 20, best)  k-fold   \n77  digits  Decision Tree Classifier  (10, 40, random)  k-fold   \n79  digits  Decision Tree Classifier    (10, 40, best)  k-fold   \n81  digits  Decision Tree Classifier   (15, 2, random)  k-fold   \n83  digits  Decision Tree Classifier     (15, 2, best)  k-fold   \n85  digits  Decision Tree Classifier  (15, 20, random)  k-fold   \n87  digits  Decision Tree Classifier    (15, 20, best)  k-fold   \n89  digits  Decision Tree Classifier  (15, 40, random)  k-fold   \n91  digits  Decision Tree Classifier    (15, 40, best)  k-fold   \n\n                                           accuracy  \\\n7   m: 0.9883209532652429 std: 0.007323832501573226   \n9   m: 0.9805277004023523 std: 0.007241231361602902   \n11  m: 0.9771850820179511 std: 0.008687630086523833   \n15  m: 0.8324945837202105 std: 0.009286635323422067   \n19  m: 0.9410229031259671 std: 0.015849668296257387   \n57     m: 0.682799442896936 std: 0.0225789955736832   \n59  m: 0.6521990095945527 std: 0.029293764851288196   \n61  m: 0.6750278551532034 std: 0.040755563742608684   \n63   m: 0.642189724543485 std: 0.026859596447899876   \n65   m: 0.6282559579077684 std: 0.04962782791262363   \n67  m: 0.6271649644073042 std: 0.022340010709646117   \n69  m: 0.8492169606932837 std: 0.024701250873822116   \n71  m: 0.8497415660786135 std: 0.016289255420700997   \n73  m: 0.7334292788610337 std: 0.020905478914734647   \n75   m: 0.7879712163416899 std: 0.01638106112774851   \n77  m: 0.6956360259981429 std: 0.030311998503533933   \n79   m: 0.7551593933766635 std: 0.02118747834909684   \n81    m: 0.8480857319715259 std: 0.0160451900425344   \n83  m: 0.8503002166511916 std: 0.009784061096593345   \n85  m: 0.7334292788610337 std: 0.020905478914734647   \n87   m: 0.7879712163416899 std: 0.01638106112774851   \n89  m: 0.6956360259981429 std: 0.030311998503533933   \n91   m: 0.7551593933766635 std: 0.02118747834909684   \n\n                                          precision  \\\n7    m: 0.9888385412595939 std: 0.00712739147876576   \n9    m: 0.9816830468409415 std: 0.00662931853158472   \n11  m: 0.9786983227511679 std: 0.007575736564379982   \n15  m: 0.8598088622118409 std: 0.015147678383072103   \n19   m: 0.9472330796425998 std: 0.01371753706347739   \n57   m: 0.717660567564935 std: 0.026132446284686445   \n59   m: 0.7298174310895975 std: 0.01717008365700091   \n61  m: 0.6950497115958991 std: 0.061857032803490745   \n63    m: 0.703735266738326 std: 0.01501969790860612   \n65   m: 0.6253692157304211 std: 0.05839129334704999   \n67   m: 0.6660513441822741 std: 0.02980445680574132   \n69  m: 0.8535964619626707 std: 0.024247845316340284   \n71  m: 0.8559045305923447 std: 0.016949978229067093   \n73   m: 0.7394966477817702 std: 0.02134785363906439   \n75  m: 0.7966323249656977 std: 0.019183878519583475   \n77   m: 0.7156065230428587 std: 0.03517987997097763   \n79  m: 0.7708872928512271 std: 0.018327983630086836   \n81  m: 0.8518270691602231 std: 0.014618370518263432   \n83  m: 0.8570756527976207 std: 0.010812556072823007   \n85   m: 0.7394966477817702 std: 0.02134785363906439   \n87  m: 0.7966323249656977 std: 0.019183878519583475   \n89   m: 0.7156065230428587 std: 0.03517987997097763   \n91  m: 0.7708872928512271 std: 0.018327983630086836   \n\n                                             recall  \\\n7   m: 0.9882972972972972 std: 0.007208664307978579   \n9    m: 0.9804048249930603 std: 0.00715395193374626   \n11  m: 0.9770371716254068 std: 0.008674693211716449   \n15  m: 0.8325454614278144 std: 0.009764788694682724   \n19  m: 0.9410189264895147 std: 0.015777826142176866   \n57  m: 0.6822451106568753 std: 0.022306835943359964   \n59  m: 0.6520541549953315 std: 0.028721061472361847   \n61    m: 0.674860019683549 std: 0.04133979548873456   \n63  m: 0.6420215509627274 std: 0.026807715646732715   \n65  m: 0.6283112019582608 std: 0.050742761166004666   \n67  m: 0.6270297019708784 std: 0.022343553593636677   \n69   m: 0.848803896333308 std: 0.024983989383474584   \n71  m: 0.8496446109975521 std: 0.016132101050840803   \n73   m: 0.7331400055517703 std: 0.02089872408546371   \n75    m: 0.7882291114644057 std: 0.0162673398542481   \n77   m: 0.6946652282534636 std: 0.03080685318605075   \n79   m: 0.754918641330406 std: 0.021705452983571242   \n81   m: 0.847657531481061 std: 0.016500416901784897   \n83  m: 0.8501242334771746 std: 0.009676746964727485   \n85   m: 0.7331400055517703 std: 0.02089872408546371   \n87    m: 0.7882291114644057 std: 0.0162673398542481   \n89   m: 0.6946652282534636 std: 0.03080685318605075   \n91   m: 0.754918641330406 std: 0.021705452983571242   \n\n                                        time training  \\\n7   total: 0.10275459289550781 values: [0.02094388...   \n9   total: 0.10275840759277344 values: [0.02194023...   \n11  total: 0.09970474243164062 values: [0.01994562...   \n15  total: 0.01199197769165039 values: [0.00199556...   \n19  total: 0.13663363456726074 values: [0.02892208...   \n57  total: 0.028920888900756836 values: [0.0049846...   \n59  total: 0.06482982635498047 values: [0.01196933...   \n61  total: 0.021940946578979492 values: [0.0049874...   \n63  total: 0.04886913299560547 values: [0.00997281...   \n65  total: 0.01900506019592285 values: [0.00398517...   \n67  total: 0.04684734344482422 values: [0.00897574...   \n69  total: 0.03191232681274414 values: [0.00694966...   \n71  total: 0.07774758338928223 values: [0.01592493...   \n73  total: 0.022938013076782227 values: [0.0039889...   \n75  total: 0.06482529640197754 values: [0.01296425...   \n77  total: 0.020895957946777344 values: [0.0049526...   \n79  total: 0.05485177040100098 values: [0.01097035...   \n81  total: 0.03197884559631348 values: [0.00698113...   \n83  total: 0.08279752731323242 values: [0.0169549 ...   \n85  total: 0.022937297821044922 values: [0.0039892...   \n87  total: 0.06186532974243164 values: [0.01196742...   \n89  total: 0.019953012466430664 values: [0.0039923...   \n91  total: 0.054949045181274414 values: [0.0109748...   \n\n                                         time testing  \n7   total: 0.3311154842376709 values: [0.06682134 ...  \n9   total: 0.337064266204834 values: [0.07081056 0...  \n11  total: 0.32419276237487793 values: [0.06382966...  \n15  total: 0.01297307014465332 values: [0.00299144...  \n19  total: 0.00698399543762207 values: [0.00099802...  \n57  total: 0.009973526000976562 values: [0.0019960...  \n59  total: 0.00997304916381836 values: [0.00199485...  \n61  total: 0.009973526000976562 values: [0.0029909...  \n63  total: 0.00997304916381836 values: [0.00199485...  \n65  total: 0.008919239044189453 values: [0.0019950...  \n67  total: 0.009006738662719727 values: [0.0019977...  \n69  total: 0.007977724075317383 values: [0.0009980...  \n71  total: 0.008978128433227539 values: [0.0019953...  \n73  total: 0.008977651596069336 values: [0.0019950...  \n75  total: 0.00897359848022461 values: [0.00099754...  \n77  total: 0.0080108642578125 values: [0.00099778 ...  \n79  total: 0.008977174758911133 values: [0.0009977...  \n81  total: 0.006985902786254883 values: [0.0009975...  \n83  total: 0.006951332092285156 values: [0.0009977...  \n85  total: 0.006983041763305664 values: [0.0019948...  \n87  total: 0.0079803466796875 values: [0.00099802 ...  \n89  total: 0.009967565536499023 values: [0.0019919...  \n91  total: 0.005019426345825195 values: [0.0009949...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=3</td>\n      <td>k-fold</td>\n      <td>m: 0.9883209532652429 std: 0.007323832501573226</td>\n      <td>m: 0.9888385412595939 std: 0.00712739147876576</td>\n      <td>m: 0.9882972972972972 std: 0.007208664307978579</td>\n      <td>total: 0.10275459289550781 values: [0.02094388...</td>\n      <td>total: 0.3311154842376709 values: [0.06682134 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9805277004023523 std: 0.007241231361602902</td>\n      <td>m: 0.9816830468409415 std: 0.00662931853158472</td>\n      <td>m: 0.9804048249930603 std: 0.00715395193374626</td>\n      <td>total: 0.10275840759277344 values: [0.02194023...</td>\n      <td>total: 0.337064266204834 values: [0.07081056 0...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=15</td>\n      <td>k-fold</td>\n      <td>m: 0.9771850820179511 std: 0.008687630086523833</td>\n      <td>m: 0.9786983227511679 std: 0.007575736564379982</td>\n      <td>m: 0.9770371716254068 std: 0.008674693211716449</td>\n      <td>total: 0.09970474243164062 values: [0.01994562...</td>\n      <td>total: 0.32419276237487793 values: [0.06382966...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.8324945837202105 std: 0.009286635323422067</td>\n      <td>m: 0.8598088622118409 std: 0.015147678383072103</td>\n      <td>m: 0.8325454614278144 std: 0.009764788694682724</td>\n      <td>total: 0.01199197769165039 values: [0.00199556...</td>\n      <td>total: 0.01297307014465332 values: [0.00299144...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9410229031259671 std: 0.015849668296257387</td>\n      <td>m: 0.9472330796425998 std: 0.01371753706347739</td>\n      <td>m: 0.9410189264895147 std: 0.015777826142176866</td>\n      <td>total: 0.13663363456726074 values: [0.02892208...</td>\n      <td>total: 0.00698399543762207 values: [0.00099802...</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.682799442896936 std: 0.0225789955736832</td>\n      <td>m: 0.717660567564935 std: 0.026132446284686445</td>\n      <td>m: 0.6822451106568753 std: 0.022306835943359964</td>\n      <td>total: 0.028920888900756836 values: [0.0049846...</td>\n      <td>total: 0.009973526000976562 values: [0.0019960...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6521990095945527 std: 0.029293764851288196</td>\n      <td>m: 0.7298174310895975 std: 0.01717008365700091</td>\n      <td>m: 0.6520541549953315 std: 0.028721061472361847</td>\n      <td>total: 0.06482982635498047 values: [0.01196933...</td>\n      <td>total: 0.00997304916381836 values: [0.00199485...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6750278551532034 std: 0.040755563742608684</td>\n      <td>m: 0.6950497115958991 std: 0.061857032803490745</td>\n      <td>m: 0.674860019683549 std: 0.04133979548873456</td>\n      <td>total: 0.021940946578979492 values: [0.0049874...</td>\n      <td>total: 0.009973526000976562 values: [0.0029909...</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.642189724543485 std: 0.026859596447899876</td>\n      <td>m: 0.703735266738326 std: 0.01501969790860612</td>\n      <td>m: 0.6420215509627274 std: 0.026807715646732715</td>\n      <td>total: 0.04886913299560547 values: [0.00997281...</td>\n      <td>total: 0.00997304916381836 values: [0.00199485...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6282559579077684 std: 0.04962782791262363</td>\n      <td>m: 0.6253692157304211 std: 0.05839129334704999</td>\n      <td>m: 0.6283112019582608 std: 0.050742761166004666</td>\n      <td>total: 0.01900506019592285 values: [0.00398517...</td>\n      <td>total: 0.008919239044189453 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(5, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.6271649644073042 std: 0.022340010709646117</td>\n      <td>m: 0.6660513441822741 std: 0.02980445680574132</td>\n      <td>m: 0.6270297019708784 std: 0.022343553593636677</td>\n      <td>total: 0.04684734344482422 values: [0.00897574...</td>\n      <td>total: 0.009006738662719727 values: [0.0019977...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8492169606932837 std: 0.024701250873822116</td>\n      <td>m: 0.8535964619626707 std: 0.024247845316340284</td>\n      <td>m: 0.848803896333308 std: 0.024983989383474584</td>\n      <td>total: 0.03191232681274414 values: [0.00694966...</td>\n      <td>total: 0.007977724075317383 values: [0.0009980...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8497415660786135 std: 0.016289255420700997</td>\n      <td>m: 0.8559045305923447 std: 0.016949978229067093</td>\n      <td>m: 0.8496446109975521 std: 0.016132101050840803</td>\n      <td>total: 0.07774758338928223 values: [0.01592493...</td>\n      <td>total: 0.008978128433227539 values: [0.0019953...</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.022938013076782227 values: [0.0039889...</td>\n      <td>total: 0.008977651596069336 values: [0.0019950...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.06482529640197754 values: [0.01296425...</td>\n      <td>total: 0.00897359848022461 values: [0.00099754...</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.020895957946777344 values: [0.0049526...</td>\n      <td>total: 0.0080108642578125 values: [0.00099778 ...</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(10, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.05485177040100098 values: [0.01097035...</td>\n      <td>total: 0.008977174758911133 values: [0.0009977...</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.8480857319715259 std: 0.0160451900425344</td>\n      <td>m: 0.8518270691602231 std: 0.014618370518263432</td>\n      <td>m: 0.847657531481061 std: 0.016500416901784897</td>\n      <td>total: 0.03197884559631348 values: [0.00698113...</td>\n      <td>total: 0.006985902786254883 values: [0.0009975...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 2, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.8503002166511916 std: 0.009784061096593345</td>\n      <td>m: 0.8570756527976207 std: 0.010812556072823007</td>\n      <td>m: 0.8501242334771746 std: 0.009676746964727485</td>\n      <td>total: 0.08279752731323242 values: [0.0169549 ...</td>\n      <td>total: 0.006951332092285156 values: [0.0009977...</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.7334292788610337 std: 0.020905478914734647</td>\n      <td>m: 0.7394966477817702 std: 0.02134785363906439</td>\n      <td>m: 0.7331400055517703 std: 0.02089872408546371</td>\n      <td>total: 0.022937297821044922 values: [0.0039892...</td>\n      <td>total: 0.006983041763305664 values: [0.0019948...</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 20, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7879712163416899 std: 0.01638106112774851</td>\n      <td>m: 0.7966323249656977 std: 0.019183878519583475</td>\n      <td>m: 0.7882291114644057 std: 0.0162673398542481</td>\n      <td>total: 0.06186532974243164 values: [0.01196742...</td>\n      <td>total: 0.0079803466796875 values: [0.00099802 ...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, random)</td>\n      <td>k-fold</td>\n      <td>m: 0.6956360259981429 std: 0.030311998503533933</td>\n      <td>m: 0.7156065230428587 std: 0.03517987997097763</td>\n      <td>m: 0.6946652282534636 std: 0.03080685318605075</td>\n      <td>total: 0.019953012466430664 values: [0.0039923...</td>\n      <td>total: 0.009967565536499023 values: [0.0019919...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>digits</td>\n      <td>Decision Tree Classifier</td>\n      <td>(15, 40, best)</td>\n      <td>k-fold</td>\n      <td>m: 0.7551593933766635 std: 0.02118747834909684</td>\n      <td>m: 0.7708872928512271 std: 0.018327983630086836</td>\n      <td>m: 0.754918641330406 std: 0.021705452983571242</td>\n      <td>total: 0.054949045181274414 values: [0.0109748...</td>\n      <td>total: 0.005019426345825195 values: [0.0009949...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Again,  acccuracy, precision and recall were good across all approaches.\n",
    "In this specific case, also the perceptron yielded notable better results.\n",
    "\n",
    "Again, the data set may  be prone to ceiling effects for measuring effectiveness for such image recognition tasks.\n",
    "\n",
    "### Efficiency\n",
    "Similar to the Iris dataset the training and testing time measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks.\n",
    "Larger and more complex datasets would yield more meaningful results in terms of efficiency."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}