{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLE - Exercise 2 - Comparative Experimentation\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "## Assignment\n",
    "In this exercise, you shall experiment with a number of (simple) algorithms on several datasets. The aim is to get a feeling how well each of these algorithms works, and whether there are differences depending on the dataset.\n",
    "\n",
    "The datasets are\n",
    "* [Iris](https://archive.ics.uci.edu/ml/datasets/Iris), for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "* [Handwritten digits](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits), of which we only use the test set of 1797 instances; for Python, use http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)\n",
    "* If you are a group of three (see below): [Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)); skip the ID field; in Python: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "\n",
    "The classifiers you shall use are\n",
    "* k-NN (with 3 different values for k)\n",
    "* Naive Bayes\n",
    "* Perceptron, and\n",
    "* Decision Trees with 3 different parameter settings (e.g. some pre-pruning setting, different split criterion, ...)\n",
    "\n",
    "For each dataset, you shall train and evaluate each classifier (with parameter variations), and then compute several evaluation metrics\n",
    "* Effectiveness: Accuracy, and 1 more of your choice (precision, recall, F1, ...\n",
    "* Efficiency: runtime for training & testing\n",
    "* As evaluation set splitting technique, you shall use once the holdout method with 2/3 training and the rest for testing, and once cross validation with 5 folds.\n",
    "\n",
    "You shall present these results in a tabular form, with one table for each dataset & splitting combination approach.\n",
    "\n",
    "Iris/5-folds | Accuracy | Precision| Training time | Testing time\n",
    "---|---|---|---|---|---\n",
    "k-NN (3-NN) | .85 | .82 | 0.1 sec | 27 sec\n",
    "Naive Bayes | .72 | .82 | 1 sec | 2 sec\n",
    "Decision Tree | .92 | .76 | 5 sec | 2 sec\n",
    "... | ... | ...| ... | ...\n",
    "\n",
    "Then describe the results, and analyse e.g.:\n",
    "* Which classifiers work best?\n",
    "* Are there differences between the datasets?\n",
    "* Are the differences in the efficiency measurements?\n",
    "* How is the runtime changing with the different data sets?\n",
    "* ...\n",
    "\n",
    "You can solve this exercise alone, or in a group of two students. If you form a group, you need to extend your scope, by\n",
    "* Adding a third dataset, namely breast cancer wisconsin\n",
    "* For k-NN, using 5 different values for k instead of 3, and use both weighted and uniform distance (i.e. a total of 10 combinations); for Decision Trees, also add 3 more parameter variations\n",
    "* Adding a third efficiency evaluation metric\n",
    "\n",
    "## Deliverables\n",
    "Your submission shall contain\n",
    "* The textual report\n",
    "* All code samples and\n",
    "* All data sets (if not already included in your software package, e.g. Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sources used\n",
    "* Scikit documentation\n",
    "* https://simonhessner.de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-multi-class-problem/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Imports and Helper Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#General Imports\n",
    "import numpy as numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "#Global variables\n",
    "randomState=24  # change the state with the numeric parts of your matrikelnummer; if you are in a group, use the sume of the numeric parts\n",
    "                # se19m024\n",
    "datasets = [('iris', datasets.load_iris()),('digits', datasets.load_digits())]\n",
    "averagingApproach = 'macro'\n",
    "zero_divisionApproach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averagingApproach, zero_division=zero_divisionApproach),\n",
    "            'Recall': make_scorer(recall_score, average=averagingApproach, zero_division=zero_divisionApproach)}\n",
    "\n",
    "#Helper funcitons\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(numpy.average(results)) + \" std: \" + str(numpy.std(results)) # + \" values: \" + str(results)\n",
    "\n",
    "def parse_k_fold_timings(results):\n",
    "    return \"total: \" + str(numpy.sum(results)) + \" values: \" + str(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## k-NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "knn_results = []\n",
    "\n",
    "# parameters for k-NN\n",
    "n_neighbors = [5,10,20]\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        # train the k-NN\n",
    "        classifier = neighbors.KNeighborsClassifier(n)\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0 )\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'kNN',\n",
    "            'arguments': 'n=' + str(n),\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        knn_results.append(result)\n",
    "\n",
    "knn_results_df = pd.DataFrame(knn_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "The results below show extremely high accuracy for kNN  in the Iris dataset both with N values of 5, 10 and 20. However, best results were yielded for a N value of 2.\n",
    "\n",
    "Additionally, results of the k-fold approach show good consistency of results across 5 folds. Interestingly, the results start shifting towards the model with n=10."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris      kNN       n=5  holdout     0.96  0.958333  0.968254   \n2    iris      kNN      n=10  holdout     0.92  0.925926  0.936508   \n4    iris      kNN      n=20  holdout     0.88       0.9  0.904762   \n\n  time training time testing  \n0   0.000997066   0.00299168  \n2             0   0.00199103  \n4             0   0.00199485  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.96</td>\n      <td>0.958333</td>\n      <td>0.968254</td>\n      <td>0.000997066</td>\n      <td>0.00299168</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.92</td>\n      <td>0.925926</td>\n      <td>0.936508</td>\n      <td>0</td>\n      <td>0.00199103</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.88</td>\n      <td>0.9</td>\n      <td>0.904762</td>\n      <td>0</td>\n      <td>0.00199485</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris      kNN       n=5  k-fold   \n3    iris      kNN      n=10  k-fold   \n5    iris      kNN      n=20  k-fold   \n\n                                         accuracy  \\\n1               m: 0.96 std: 0.038873012632301994   \n3  m: 0.9733333333333334 std: 0.05333333333333332   \n5  m: 0.9466666666666667 std: 0.04521553322083511   \n\n                                         precision  \\\n1   m: 0.9610774410774411 std: 0.03826764858710283   \n3               m: 0.975 std: 0.049999999999999996   \n5  m: 0.9517676767676768 std: 0.042228383872089235   \n\n                                            recall  \\\n1                 m: 0.96 std: 0.03887301263230201   \n3  m: 0.9733333333333334 std: 0.053333333333333365   \n5   m: 0.9466666666666667 std: 0.04521553322083516   \n\n                                       time training  \\\n1  total: 0.0010044574737548828 values: [0.      ...   \n3  total: 0.001995563507080078 values: [0.       ...   \n5  total: 0.002045869827270508 values: [0.0010283...   \n\n                                        time testing  \n1  total: 0.015953540802001953 values: [0.0049872...  \n3  total: 0.012933015823364258 values: [0.0029604...  \n5  total: 0.012882471084594727 values: [0.0029881...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.96 std: 0.038873012632301994</td>\n      <td>m: 0.9610774410774411 std: 0.03826764858710283</td>\n      <td>m: 0.96 std: 0.03887301263230201</td>\n      <td>total: 0.0010044574737548828 values: [0.      ...</td>\n      <td>total: 0.015953540802001953 values: [0.0049872...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9733333333333334 std: 0.05333333333333332</td>\n      <td>m: 0.975 std: 0.049999999999999996</td>\n      <td>m: 0.9733333333333334 std: 0.053333333333333365</td>\n      <td>total: 0.001995563507080078 values: [0.       ...</td>\n      <td>total: 0.012933015823364258 values: [0.0029604...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>iris</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083511</td>\n      <td>m: 0.9517676767676768 std: 0.042228383872089235</td>\n      <td>m: 0.9466666666666667 std: 0.04521553322083516</td>\n      <td>total: 0.002045869827270508 values: [0.0010283...</td>\n      <td>total: 0.012882471084594727 values: [0.0029881...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='holdout')])\n",
    "\n",
    "display(\"K-Fold\", knn_results_df[(knn_results_df['dataset']=='iris') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "Similar to the Iris dataset, the results below also show extremely high accuracy for kNN for a image recognition dataset both with N values of 5, 10 and 20. However, best results were yielded for a N value of 10.\n",
    "\n",
    "Additionally, results of the k-fold approach again show good consistency of results across 5 folds.\n",
    "Consistent with the findings for the Iris dataset, the k-fold approach again shows better results for higher n parameters than the simple holdout solution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset approach arguments    split  accuracy precision    recall  \\\n6   digits      kNN       n=5  holdout  0.983165  0.983364  0.983174   \n8   digits      kNN      n=10  holdout  0.976431  0.976702  0.976281   \n10  digits      kNN      n=20  holdout  0.961279  0.962286  0.961089   \n\n   time training time testing  \n6      0.0179744     0.100703  \n8      0.0179191     0.103723  \n10     0.0179517     0.103723  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>holdout</td>\n      <td>0.983165</td>\n      <td>0.983364</td>\n      <td>0.983174</td>\n      <td>0.0179744</td>\n      <td>0.100703</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>holdout</td>\n      <td>0.976431</td>\n      <td>0.976702</td>\n      <td>0.976281</td>\n      <td>0.0179191</td>\n      <td>0.103723</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>holdout</td>\n      <td>0.961279</td>\n      <td>0.962286</td>\n      <td>0.961089</td>\n      <td>0.0179517</td>\n      <td>0.103723</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   dataset approach arguments   split  \\\n7   digits      kNN       n=5  k-fold   \n9   digits      kNN      n=10  k-fold   \n11  digits      kNN      n=20  k-fold   \n\n                                           accuracy  \\\n7   m: 0.9883163107397092 std: 0.005388572629804117   \n9   m: 0.9805277004023523 std: 0.007241231361602902   \n11  m: 0.9705060352831941 std: 0.006724967766856801   \n\n                                          precision  \\\n7   m: 0.9887866449971712 std: 0.005222598238459717   \n9    m: 0.9816830468409415 std: 0.00662931853158472   \n11  m: 0.9717214434156635 std: 0.006292571449491544   \n\n                                              recall  \\\n7   m: 0.9882804905746081 std: 0.0053145264097686756   \n9     m: 0.9804048249930603 std: 0.00715395193374626   \n11    m: 0.9702434451257981 std: 0.00681107277803136   \n\n                                        time training  \\\n7   total: 0.1127316951751709 values: [0.02193904 ...   \n9   total: 0.1077125072479248 values: [0.02293897 ...   \n11  total: 0.1116938591003418 values: [0.02393508 ...   \n\n                                         time testing  \n7   total: 0.3489997386932373 values: [0.06978202 ...  \n9   total: 0.3550546169281006 values: [0.07181168 ...  \n11  total: 0.36203479766845703 values: [0.07280636...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=5</td>\n      <td>k-fold</td>\n      <td>m: 0.9883163107397092 std: 0.005388572629804117</td>\n      <td>m: 0.9887866449971712 std: 0.005222598238459717</td>\n      <td>m: 0.9882804905746081 std: 0.0053145264097686756</td>\n      <td>total: 0.1127316951751709 values: [0.02193904 ...</td>\n      <td>total: 0.3489997386932373 values: [0.06978202 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=10</td>\n      <td>k-fold</td>\n      <td>m: 0.9805277004023523 std: 0.007241231361602902</td>\n      <td>m: 0.9816830468409415 std: 0.00662931853158472</td>\n      <td>m: 0.9804048249930603 std: 0.00715395193374626</td>\n      <td>total: 0.1077125072479248 values: [0.02293897 ...</td>\n      <td>total: 0.3550546169281006 values: [0.07181168 ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>digits</td>\n      <td>kNN</td>\n      <td>n=20</td>\n      <td>k-fold</td>\n      <td>m: 0.9705060352831941 std: 0.006724967766856801</td>\n      <td>m: 0.9717214434156635 std: 0.006292571449491544</td>\n      <td>m: 0.9702434451257981 std: 0.00681107277803136</td>\n      <td>total: 0.1116938591003418 values: [0.02393508 ...</td>\n      <td>total: 0.36203479766845703 values: [0.07280636...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='holdout')])\n",
    "\n",
    "display(\"K-Fold\", knn_results_df[(knn_results_df['dataset']=='digits') & (knn_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "bayes_results = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = naive_bayes.GaussianNB()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                        scoring = scoring,\n",
    "                        cv = number_of_folds,\n",
    "                        error_score = 0 )\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'bayes',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    bayes_results.append(result)\n",
    "\n",
    "bayes_results_df = pd.DataFrame(bayes_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "\n",
    "Results below indicate good accuracy, precision and recall for the dataset. Accuracy is a bit lower than for k-NN but still very good.\n",
    "\n",
    "Results seem to be highly consistent: k-fold analysis reveals only a limited standard deviation for the results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments    split accuracy precision    recall  \\\n0    iris    bayes      none  holdout      0.9   0.90305  0.912698   \n\n  time training time testing  \n0    0.00100899            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.9</td>\n      <td>0.90305</td>\n      <td>0.912698</td>\n      <td>0.00100899</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n1    iris    bayes      none  k-fold   \n\n                                         accuracy  \\\n1  m: 0.9533333333333334 std: 0.03399346342395189   \n\n                                        precision  \\\n1  m: 0.9550168350168351 std: 0.03375719358407477   \n\n                                          recall  \\\n1  m: 0.9533333333333334 std: 0.0339934634239519   \n\n                                       time training  \\\n1  total: 0.0009975433349609375 values: [0.000997...   \n\n                                        time testing  \n1  total: 0.009973526000976562 values: [0.0019946...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9533333333333334 std: 0.03399346342395189</td>\n      <td>m: 0.9550168350168351 std: 0.03375719358407477</td>\n      <td>m: 0.9533333333333334 std: 0.0339934634239519</td>\n      <td>total: 0.0009975433349609375 values: [0.000997...</td>\n      <td>total: 0.009973526000976562 values: [0.0019946...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='holdout')])\n",
    "display(\"K-Fold\", bayes_results_df[(bayes_results_df['dataset']=='iris') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "Similar to the Iris dataset, Bayes yielded also sufficient accuracy, precision and recall for the digits dataset. Again, accuracy is a bit lower than for k-NN but still very good.\n",
    "\n",
    "The difference between the Iris and Digit dataset is noteworthy however. It seems like Bayes is not a similarly good approach for this data set. This may be related to the much higher dimensionality of the digit dataset.\n",
    "\n",
    "Also for this dataset, consistency of results as measured by a five fold cross validation seems good."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments    split  accuracy precision    recall  \\\n2  digits    bayes      none  holdout  0.833333  0.850641  0.833908   \n\n  time training time testing  \n2    0.00199437   0.00199461  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.833333</td>\n      <td>0.850641</td>\n      <td>0.833908</td>\n      <td>0.00199437</td>\n      <td>0.00199461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset approach arguments   split  \\\n3  digits    bayes      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.8324945837202105 std: 0.009286635323422067   \n\n                                         precision  \\\n3  m: 0.8598088622118409 std: 0.015147678383072103   \n\n                                            recall  \\\n3  m: 0.8325454614278144 std: 0.009764788694682724   \n\n                                       time training  \\\n3  total: 0.014959573745727539 values: [0.0029916...   \n\n                                        time testing  \n3  total: 0.014960050582885742 values: [0.0029919...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>bayes</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.8324945837202105 std: 0.009286635323422067</td>\n      <td>m: 0.8598088622118409 std: 0.015147678383072103</td>\n      <td>m: 0.8325454614278144 std: 0.009764788694682724</td>\n      <td>total: 0.014959573745727539 values: [0.0029916...</td>\n      <td>total: 0.014960050582885742 values: [0.0029919...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='holdout')])\n",
    "display(\"K-Fold\", bayes_results_df[(bayes_results_df['dataset']=='digits') & (bayes_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "perceptron_results = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    # train the bayes model\n",
    "    classifier = linear_model.Perceptron()\n",
    "    classifier.random_state = randomState\n",
    "    start_time_train = time.time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end_time_train = time.time()\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    start_time_test = time.time()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time_test = time.time()\n",
    "\n",
    "    # Compute metrics for holdout\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach':'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'holdout',\n",
    "        'accuracy':acc,\n",
    "        'precision':precision,\n",
    "        'recall':recall,\n",
    "        'time training':end_time_train-start_time_train,\n",
    "        'time testing':end_time_test-start_time_test\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "    # Compute metrics for k fold\n",
    "    scores = cross_validate(classifier, data, target,\n",
    "                    scoring = scoring,\n",
    "                    cv = number_of_folds,\n",
    "                    error_score = 0 )\n",
    "    result = pd.Series({\n",
    "        'dataset': dataset[0],\n",
    "        'approach': 'perceptron',\n",
    "        'arguments': 'none',\n",
    "        'split': 'k-fold',\n",
    "        'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "        'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "        'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "        'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "        'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "    })\n",
    "    perceptron_results.append(result)\n",
    "\n",
    "perceptron_results_df = pd.DataFrame(perceptron_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "The Perceptron yields as only approach applied in this exercise insufficient results. Only 34% of all test set items were correctly assigned.\n",
    "\n",
    "Interestingly, we see a great divergence between holdout and k-fold results. This may be related to the higher variance of results in the 5 folds.\n",
    "Potentially, our holdout results were caused by a significantly bad starting position."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split accuracy precision recall  \\\n0    iris  perceptron      none  holdout     0.34  0.432624    0.4   \n\n  time training time testing  \n0    0.00198674   0.00100946  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.34</td>\n      <td>0.432624</td>\n      <td>0.4</td>\n      <td>0.00198674</td>\n      <td>0.00100946</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split                          accuracy  \\\n1    iris  perceptron      none  k-fold  m: 0.74 std: 0.10413666234542207   \n\n                                        precision  \\\n1  m: 0.6742889463477699 std: 0.19998100699035673   \n\n                             recall  \\\n1  m: 0.74 std: 0.10413666234542203   \n\n                                       time training  \\\n1  total: 0.010969877243041992 values: [0.0029919...   \n\n                                        time testing  \n1  total: 0.006981372833251953 values: [0.0009968...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>iris</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.74 std: 0.10413666234542207</td>\n      <td>m: 0.6742889463477699 std: 0.19998100699035673</td>\n      <td>m: 0.74 std: 0.10413666234542203</td>\n      <td>total: 0.010969877243041992 values: [0.0029919...</td>\n      <td>total: 0.006981372833251953 values: [0.0009968...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='holdout')])\n",
    "display(\"K-Fold\", perceptron_results_df[(perceptron_results_df['dataset']=='iris') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "\n",
    "Compared to the perceptron results found for the Iris dataset, the perceptron yielded far superior results for the digit dataset.\n",
    "\n",
    "This may be related to the fact that Perceptrons yield good results for these kind of higher dimensional image analysis tasks (i.e. Tariq Rashid, 2017).\n",
    "\n",
    "Additionally, results seem to be more consistent than for the lower dimensional data of the Iris dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Holdout'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments    split  accuracy precision   recall  \\\n2  digits  perceptron      none  holdout  0.939394   0.94141  0.93962   \n\n  time training time testing  \n2     0.0259304            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>holdout</td>\n      <td>0.939394</td>\n      <td>0.94141</td>\n      <td>0.93962</td>\n      <td>0.0259304</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'K-Fold'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  dataset    approach arguments   split  \\\n3  digits  perceptron      none  k-fold   \n\n                                          accuracy  \\\n3  m: 0.9410229031259671 std: 0.015849668296257387   \n\n                                        precision  \\\n3  m: 0.9472330796425998 std: 0.01371753706347739   \n\n                                            recall  \\\n3  m: 0.9410189264895147 std: 0.015777826142176866   \n\n                                       time training  \\\n3  total: 0.16163325309753418 values: [0.03194761...   \n\n                                        time testing  \n3  total: 0.00994253158569336 values: [0.00199556...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>approach</th>\n      <th>arguments</th>\n      <th>split</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>time training</th>\n      <th>time testing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>digits</td>\n      <td>perceptron</td>\n      <td>none</td>\n      <td>k-fold</td>\n      <td>m: 0.9410229031259671 std: 0.015849668296257387</td>\n      <td>m: 0.9472330796425998 std: 0.01371753706347739</td>\n      <td>m: 0.9410189264895147 std: 0.015777826142176866</td>\n      <td>total: 0.16163325309753418 values: [0.03194761...</td>\n      <td>total: 0.00994253158569336 values: [0.00199556...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\"Holdout\", perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='holdout')])\n",
    "display(\"K-Fold\", perceptron_results_df[(perceptron_results_df['dataset']=='digits') & (perceptron_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \"\\n, min Samples/Leaf: \" + str(argumentsTuple[1]) + \\\n",
    "           \"\\n, Splitting: \" + argumentsTuple[2]\n",
    "\n",
    "decision_tree_results = []\n",
    "\n",
    "# Parameters for the decision tree\n",
    "max_depth_arguments = [5,10,15]\n",
    "min_samples_leaf_arguments = [2,20,50,100]\n",
    "splitting_approaches_arguments = ['random', 'best']\n",
    "argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                        min_samples_leaf_arguments,\n",
    "                                        splitting_approaches_arguments))\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Shuffle our input data\n",
    "    data, target = shuffle(dataset[1].data, dataset[1].target, random_state=randomState)\n",
    "\n",
    "    # Prepare a train/test set split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=(randomState+1))\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "        splitting_approach = argumentTuple[2]\n",
    "\n",
    "        # train the k-NN\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = splitting_approach)\n",
    "\n",
    "        classifier.random_state = randomState\n",
    "        start_time_train = time.time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        end_time_train = time.time()\n",
    "\n",
    "        # predict the test set on our trained classifier\n",
    "        start_time_test = time.time()\n",
    "        y_test_predicted = classifier.predict(X_test)\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        # Compute metrics for holdout\n",
    "        acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "        recall=metrics.recall_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "        precision = metrics.precision_score(y_test, y_test_predicted, average=averagingApproach, zero_division=zero_divisionApproach)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': parse_argument_tuple_as_string(argumentTuple),\n",
    "            'split': 'holdout',\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall,\n",
    "            'time training':end_time_train-start_time_train,\n",
    "            'time testing':end_time_test-start_time_test\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "        # Compute metrics for k fold\n",
    "        scores = cross_validate(classifier, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "        result = pd.Series({\n",
    "            'dataset': dataset[0],\n",
    "            'approach':'Decision Tree Classifier',\n",
    "            'arguments': parse_argument_tuple_as_string(argumentTuple),\n",
    "            'split': 'k-fold',\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall')),\n",
    "            'time training':parse_k_fold_timings(scores.get('fit_time')),\n",
    "            'time testing':parse_k_fold_timings(scores.get('score_time'))\n",
    "        })\n",
    "        decision_tree_results.append(result)\n",
    "\n",
    "decision_tree_results_df = pd.DataFrame(decision_tree_results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iris\n",
    "\n",
    "Results of the Iris dataset show that best results are yielded for the 'best' splitting approach instead of the random splitting approach.\n",
    "\n",
    "Not surprisingly, higher `maximum_depth` values yielded better results.\n",
    "However in combination with `min_samples_leaf`, we see that the high depth is not needed and that several nodes are representing only a limited number of values.\n",
    "Even with relatively high numbers of `min_samples_leaf`, the resulting tree yields good results, that degrade only in arbitrarily high numbers (i.e. 100 as tried below).\n",
    "\n",
    "Additionally, consistency of the results seems to be good across arguments used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'load_iris'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-c0c911e50a22>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdatasetIris\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_iris\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m;\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n\u001B[0;32m      3\u001B[0m                                          \u001B[0mmax_depth\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                                          \u001B[0mmin_samples_leaf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                                          splitter = 'best')\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'load_iris'"
     ]
    }
   ],
   "source": [
    "datasetIris = datasets.load_iris()\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 20,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetIris.data, datasetIris.target), max_depth=5)\n",
    "display('Holdout', decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='holdout')])\n",
    "display('K-Fold', decision_tree_results_df[(decision_tree_results_df['dataset']=='iris') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handwritten Numbers\n",
    "As for the digits dataset, the results show high similarity to the Iris dataset.\n",
    "\n",
    "As expected, results are somewhat lower in terms of accuracy, precision and recall due to the added complexity caused by the higher number of dimensions/criteria.\n",
    "\n",
    "The results indicate that the decision tree performs best, if a maximum depth of 10 is defined. Any deeper tree seems to be resulting in an overfitted solution.\n",
    "Additionally, increased values for `min_samples_leaf` do also seem to counteract this issue. Since `max_depth` strongly interacts with the amount to which `min_samples_leaf` is relevant, this was also expected.\n",
    "\n",
    "Again, consistency of results across all parameters as measured by the deviation of the k-fold results was sufficient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasetDigits = datasets.load_digits()\n",
    "classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                         max_depth = 20,\n",
    "                                         min_samples_leaf = 20,\n",
    "                                         splitter = 'best')\n",
    "tree.plot_tree(classifier.fit(datasetDigits.data, datasetDigits.target),max_depth=3)\n",
    "\n",
    "display('Holdout', decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='holdout')])\n",
    "display('K-Fold', decision_tree_results_df[(decision_tree_results_df['dataset']=='digits') & (decision_tree_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overall Results\n",
    "## Approach Specific Findings\n",
    "Findings specific to the separate approaches and their potential interactions with the dataset they were applied on, were already discussed in the previous sections.\n",
    "\n",
    "The following will hence only focus on a comparison of the approaches."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "overall_results = knn_results + bayes_results + perceptron_results + decision_tree_results\n",
    "overall_results_df = pd.DataFrame(overall_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iris Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='iris') &\n",
    "            (overall_results_df['split']=='k-fold')])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Despite the heterogenous approaches used, acccuracy, precision and recall were good across most approaches with the notable exception of the Perceptron.\n",
    "\n",
    "The results also showed specific strengths and weaknesses of the approaches used when applied to this specific dataset: While the decision tree was well applicable for the low dimensionality of the problem, the perceptron showed some issues in dealing with the data set.\n",
    "\n",
    "However, with the high accuracy, precision and recall accross the methods applied, the data set may be prone to ceiling effects when it comes to measuring effectiveness for these categorization tasks.\n",
    "\n",
    "### Efficiency\n",
    "In the datasets used as well as in the approaches applied, the training and testing time measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks.\n",
    "\n",
    "Generally speaking, all approaches used seem to be widely applicable for similar problems without having to think about specific computational requirements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handwritten Numbers Dataset\n",
    "### Holdout"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='holdout')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Fold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(overall_results_df[\n",
    "            (overall_results_df['dataset']=='digits') &\n",
    "            (overall_results_df['split']=='k-fold')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Effectiveness\n",
    "Again, accuracy, precision and recall were good across all approaches. In this specific case, also the perceptron yielded notable better results.\n",
    "\n",
    "Most notably were the more nuanced results of the decision tree. As noted above, this is related to the higher complexity/dimensionality of a image recognition tasks, even with the low resolution of the digits dataset.\n",
    "\n",
    "Surprisingly for the author, the results were still adequate for this task despite the fact, that the issue of potential overfitting became apparent very fast, when increasing the maximum depth or the minimum number of values per Leaf/Node.\n",
    "\n",
    "Again, the still limited complexity of the data set may be prone to ceiling effects for measuring effectiveness of the approaches for image recognition tasks.\n",
    "\n",
    "### Efficiency\n",
    "Similar to the Iris dataset the training and testing times measured were low to non-measurable.\n",
    "\n",
    "Benchmarking with these limited differences across approaches would be too prone to additional confounding variables such as running background tasks and other effects not associated with the machine learning tasks.\n",
    "Larger and more complex datasets would yield more meaningful results in terms of efficiency."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}